{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NOTE: What is referred to as a dict is sometimes a df - need to fix this labelling at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import scipy\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns  # Note will call statsmodels for kde if installed on system, otherwise will use scipy\n",
    "from collections import OrderedDict\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defines dictionary of amino acid abbreviations\n",
    "\"\"\"\n",
    "aa_dict = OrderedDict({'A': 'Ala',\n",
    "                       'R': 'Arg',\n",
    "                       'N': 'Asn',\n",
    "                       'D': 'Asp',\n",
    "                       'C': 'Cys',\n",
    "                       'Q': 'Gln',\n",
    "                       'E': 'Glu',\n",
    "                       'G': 'Gly', \n",
    "                       'H': 'His',\n",
    "                       'I': 'Ile',\n",
    "                       'L': 'Leu',\n",
    "                       'K': 'Lys',\n",
    "                       'M': 'Met',\n",
    "                       'F': 'Phe',\n",
    "                       'P': 'Pro',\n",
    "                       'S': 'Ser',\n",
    "                       'T': 'Thr',\n",
    "                       'W': 'Trp',\n",
    "                       'Y': 'Tyr',\n",
    "                       'V': 'Val'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dict(dict_vals):\n",
    "    \"\"\"\n",
    "    Defines a dictionary of amino acid properties. Allows quick definition of new property dictionaries (can\n",
    "    simply copy and paste the new property values from e.g. the Amino Acid Index) \n",
    "    Input: a list (dict_vals) of property values for the 20 (alphabetically ordered) amino acids\n",
    "    Returns: a dictionary of these property values\n",
    "    \"\"\"\n",
    "    aa_dict = OrderedDict({'A': dict_vals[0],\n",
    "                           'R': dict_vals[1],\n",
    "                           'N': dict_vals[2],\n",
    "                           'D': dict_vals[3],\n",
    "                           'C': dict_vals[4],\n",
    "                           'Q': dict_vals[5],\n",
    "                           'E': dict_vals[6],\n",
    "                           'G': dict_vals[7],\n",
    "                           'H': dict_vals[8],\n",
    "                           'I': dict_vals[9],\n",
    "                           'L': dict_vals[10],\n",
    "                           'K': dict_vals[11],\n",
    "                           'M': dict_vals[12],\n",
    "                           'F': dict_vals[13],\n",
    "                           'P': dict_vals[14],\n",
    "                           'S': dict_vals[15],\n",
    "                           'T': dict_vals[16],\n",
    "                           'W': dict_vals[17],\n",
    "                           'Y': dict_vals[18],\n",
    "                           'V': dict_vals[19]})\n",
    "    return aa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(prop_list):\n",
    "    \"\"\"\n",
    "    Removes all instances of '', 'NaN' and np.nan from an input list\n",
    "    Input: a list (prop_list) to be filtered\n",
    "    Returns: the filtered list\n",
    "    \"\"\"\n",
    "    prop_remove_list = ['', 'NaN', 'nan', np.nan]\n",
    "    for prop_remove in prop_remove_list:\n",
    "        if prop_remove in prop_list:\n",
    "            prop_list = [x for x in prop_list if x != prop_remove]\n",
    "    return prop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distribution(df, aa_dict):\n",
    "    \"\"\"\n",
    "    Counts the number of each amino acid in dataframe of barrel / sandwich properties\n",
    "    Input: dataframe of barrel / sandwich properties and dictionary of amino acid abbreviations\n",
    "    Returns: dataframe of count data\n",
    "    \"\"\"\n",
    "    distribution_list = ['']*len(aa_dict.keys())\n",
    "    fasta_list = [x for x in df['fasta_seq'].tolist() if x in list(aa_dict.keys())]\n",
    "    for index, aa in enumerate(list(aa_dict.keys())):\n",
    "        count = fasta_list.count(aa)\n",
    "        distribution_list[index] = count / len(fasta_list)\n",
    "\n",
    "    df_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    df_dict['Normalised frequency'] = distribution_list\n",
    "\n",
    "    distribution_df = pd.DataFrame(df_dict)\n",
    "    return distribution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_indv_property_propensities(df, prop, aa_dict):\n",
    "    \"\"\"\n",
    "    Calculates propensities of the amino acids listed in the input dictionary for a (categorical) feature of\n",
    "    interest (e.g. 'interior' or 'exterior')\n",
    "    Input: dataframe of barrel / sandwich properties, name of the feature of interest (specified via the name of\n",
    "           the corresponding column in the input dataframe), and dictionary of amino acid abbreviations\n",
    "    Returns: dataframe of propensity values, plus dataframes of the frequencies and normalised frequencies (since\n",
    "             extreme propensity values can result from low counts)\n",
    "    \"\"\"\n",
    "    df = df[~df[prop].isin(['', 'NaN', 'nan', np.nan])]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    prop_list = list(set(df[prop].tolist()))\n",
    "    prop_list = remove_nan(prop_list)\n",
    "\n",
    "    temp_lists = {}\n",
    "    for prop_val in prop_list:\n",
    "        temp_lists['{}_propensity_list'.format(prop_val)] = ['']*len(list(aa_dict.keys()))\n",
    "        temp_lists['{}_frequency_list'.format(prop_val)] = ['']*len(list(aa_dict.keys()))\n",
    "        temp_lists['{}_normed_frequencies_list'.format(prop_val)] = ['']*len(list(aa_dict.keys()))\n",
    "\n",
    "        temp_lists['total_{}_count'.format(prop_val)] = df[prop].tolist().count(prop_val)\n",
    "\n",
    "    for index, aa in enumerate(list(aa_dict.keys())):\n",
    "        aa_df = df[df['fasta_seq'] == aa]\n",
    "        aa_df = aa_df.reset_index(drop=True)\n",
    "\n",
    "        for prop_val in prop_list:\n",
    "            temp_lists['{}_{}_count'.format(prop_val, aa)] = aa_df[prop].tolist().count(prop_val)\n",
    "\n",
    "            if(\n",
    "                min([temp_lists['{}_{}_count'.format(prop_val, aa)], temp_lists['total_{}_count'.format(prop_val)],\n",
    "                     aa_df.shape[0], df.shape[0]]) > 0\n",
    "            ):\n",
    "                temp_lists['{}_frequency_list'.format(prop_val)][index] = copy.deepcopy(temp_lists['{}_{}_count'.format(prop_val, aa)])\n",
    "\n",
    "                temp_lists['{}_{}_normed_frequencies'.format(prop_val, aa)] = (temp_lists['{}_{}_count'.format(prop_val, aa)]\n",
    "                                                                             / temp_lists['total_{}_count'.format(prop_val)])\n",
    "                temp_lists['{}_normed_frequencies_list'.format(prop_val)][index] = temp_lists['{}_{}_normed_frequencies'.format(prop_val, aa)]\n",
    "\n",
    "                temp_lists['{}_{}_propensity'.format(prop_val, aa)] = ((temp_lists['{}_{}_normed_frequencies'.format(prop_val, aa)])\n",
    "                                                                       / (aa_df.shape[0] / df.shape[0]))\n",
    "                temp_lists['{}_propensity_list'.format(prop_val)][index] = temp_lists['{}_{}_propensity'.format(prop_val, aa)]\n",
    "            else:\n",
    "                temp_lists['{}_frequency_list'.format(prop_val)][index] = np.nan\n",
    "                temp_lists['{}_normed_frequencies_list'.format(prop_val)][index] = np.nan\n",
    "                temp_lists['{}_propensity_list'.format(prop_val)][index] = np.nan\n",
    "\n",
    "    df_propensity_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    df_frequency_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    df_normed_frequencies_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    for prop_val in prop_list:\n",
    "        df_propensity_dict[prop_val] = temp_lists['{}_propensity_list'.format(prop_val)]\n",
    "        df_frequency_dict[prop_val] = temp_lists['{}_frequency_list'.format(prop_val)]\n",
    "        df_normed_frequencies_dict[prop_val] = temp_lists['{}_normed_frequencies_list'.format(prop_val)]\n",
    "\n",
    "    propensity_df = pd.DataFrame(df_propensity_dict)\n",
    "    frequency_df = pd.DataFrame(df_frequency_dict)\n",
    "    normed_frequencies_df = pd.DataFrame(df_normed_frequencies_dict)\n",
    "    \n",
    "    return propensity_df, frequency_df, normed_frequencies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_combined_property_propensities(df, props, aa_dict):\n",
    "    \"\"\"\n",
    "    Calculates propensities of the amino acids listed in the input dictionary for two or more (categorical)\n",
    "    features of interest (e.g. 'interior' and 'transmembrane', 'interior' and 'external', 'exterior' and\n",
    "    'transmembrane', or 'exterior' and 'external')\n",
    "    Input: dataframe of barrel / sandwich properties, list of names of the features of interest (specified via\n",
    "           the names of the corresponding columns in the input dataframe), and dictionary of amino acid\n",
    "           abbreviations\n",
    "    Returns: dataframe of propensity values, plus dataframes of the frequencies and normalised frequencies (since\n",
    "             extreme propensity values can result from low counts)\n",
    "    \"\"\"\n",
    "    for prop in props:\n",
    "        df = df[~df[prop].isin(['', 'NaN', 'nan', np.nan])]\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    amalgamate_list = []\n",
    "    for prop in props:\n",
    "        filtered_list = list(set(df[prop].tolist()))\n",
    "        amalgamate_list.append(filtered_list)\n",
    "    combinations = list(itertools.product(*amalgamate_list))\n",
    "    combinations = ['_'.join(tup) for tup in combinations]\n",
    "\n",
    "    for prop in props:\n",
    "        df[prop] = [str(x) for x in df[prop].tolist()]\n",
    "    df_props = pd.DataFrame({'combination': df[props].apply('_'.join, axis=1),\n",
    "                             'FASTA': df['fasta_seq']})\n",
    "\n",
    "    temp_lists = {}\n",
    "    for combination in combinations:\n",
    "        temp_lists['{}_propensity_list'.format(combination)] = ['']*len(list(aa_dict.keys()))\n",
    "        temp_lists['{}_frequency_list'.format(combination)] = ['']*len(list(aa_dict.keys()))\n",
    "        temp_lists['{}_normed_frequencies_list'.format(combination)] = ['']*len(list(aa_dict.keys()))\n",
    "\n",
    "        temp_lists['total_{}_count'.format(combination)] = df_props['combination'].tolist().count(combination)\n",
    "\n",
    "        for index, aa in enumerate(list(aa_dict.keys())):\n",
    "            aa_df = df_props[df_props['FASTA'] == aa]\n",
    "            aa_df = aa_df.reset_index(drop=True)\n",
    "            \n",
    "            temp_lists['{}_{}_count'.format(combination, aa)] = aa_df['combination'].tolist().count(combination)\n",
    "            if (\n",
    "                min([temp_lists['{}_{}_count'.format(combination, aa)],\n",
    "                     temp_lists['total_{}_count'.format(combination)], aa_df.shape[0], df.shape[0]]) > 0\n",
    "            ):\n",
    "                temp_lists['{}_frequency_list'.format(combination)][index] = copy.deepcopy(temp_lists['{}_{}_count'.format(combination, aa)])\n",
    "\n",
    "                temp_lists['{}_{}_normed_frequencies'.format(combination, aa)] = (temp_lists['{}_{}_count'.format(combination, aa)]\n",
    "                                                                                / temp_lists['total_{}_count'.format(combination)])\n",
    "                temp_lists['{}_normed_frequencies_list'.format(combination)][index] = temp_lists['{}_{}_normed_frequencies'.format(combination, aa)]\n",
    "\n",
    "                temp_lists['{}_{}_propensity'.format(combination, aa)] = ((temp_lists['{}_{}_normed_frequencies'.format(combination, aa)])\n",
    "                                                                          / (aa_df.shape[0] / df_props.shape[0]))\n",
    "                temp_lists['{}_propensity_list'.format(combination)][index] = temp_lists['{}_{}_propensity'.format(combination, aa)]\n",
    "            else:\n",
    "                temp_lists['{}_frequency_list'.format(combination)][index] = np.nan\n",
    "                temp_lists['{}_normed_frequencies_list'.format(combination)][index] = np.nan\n",
    "                temp_lists['{}_propensity_list'.format(combination)][index] = np.nan\n",
    "\n",
    "    df_propensity_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    df_frequency_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    df_normed_frequencies_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    for combination in combinations:\n",
    "        df_propensity_dict[combination] = temp_lists['{}_propensity_list'.format(combination)]\n",
    "        df_frequency_dict[combination] = temp_lists['{}_frequency_list'.format(combination)]\n",
    "        df_normed_frequencies_dict[combination] = temp_lists['{}_normed_frequencies_list'.format(combination)]\n",
    "\n",
    "    propensity_df = pd.DataFrame(df_propensity_dict)\n",
    "    frequency_df = pd.DataFrame(df_frequency_dict)\n",
    "    normed_frequencies_df = pd.DataFrame(df_normed_frequencies_dict)\n",
    "\n",
    "    return propensity_df, frequency_df, normed_frequencies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_neighbouring_pairs_list(df, interaction, aa_dict, *args):\n",
    "    \"\"\"\n",
    "    Makes a list of the amino acids in the input dataframe that form pairwise interactions at a particular\n",
    "    location (e.g. HB vs. NHB positions) or via a particular type of interaction (e.g. cation-pi, hydrogen\n",
    "    bonds, van der Waals interactions, etc.)\n",
    "    Input: dataframe of barrel / sandwich properties, name of the interaction type / location of interest\n",
    "           (specified via the name of the corresponding column in the input dataframe), and dictionary of amino\n",
    "           acid abbreviations\n",
    "    Returns: list of interacting amino acid pairs\n",
    "    \"\"\"\n",
    "    if args:\n",
    "        props = list(args)\n",
    "\n",
    "    # Makes list of amino acid pairs (of which both amino acids are in the dataframe)\n",
    "    domain_res_ids_list = []\n",
    "    for row in range(df.shape[0]):\n",
    "        domain_res_id = df['domain_ids'][row] + df['res_ids'][row]\n",
    "        domain_res_ids_list.append(domain_res_id)\n",
    "\n",
    "    neighbouring_pairs_list = []\n",
    "    repeat_pairs_list = []\n",
    "    if args:\n",
    "        props_dict = OrderedDict()\n",
    "        for prop in props:\n",
    "            props_dict[prop] = OrderedDict()\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        domain_res_id_1 = df['domain_ids'][row] + df['res_ids'][row]\n",
    "        aa_1 = df['fasta_seq'][row]\n",
    "        if args:\n",
    "            prop_val_1_list = ['']*len(props)\n",
    "            for index, prop in enumerate(props):\n",
    "                prop_val_1_list[index] = df[prop][row]\n",
    "\n",
    "        interaction_list = df[interaction][row]\n",
    "        if type(interaction_list) != list:\n",
    "            interaction_list = [interaction_list]\n",
    "        for res_id_2 in interaction_list:\n",
    "            domain_res_id_2 = df['domain_ids'][row] + res_id_2\n",
    "\n",
    "            # Only considers amino acid pairs in which both (canonical) amino acids are located in the domain\n",
    "            if domain_res_id_2 in domain_res_ids_list:\n",
    "                res_id_2_index = domain_res_ids_list.index(domain_res_id_2)\n",
    "                aa_2 = df['fasta_seq'][res_id_2_index]\n",
    "                if args:\n",
    "                    prop_val_2_list = ['']*len(props)\n",
    "                    for index, prop in enumerate(props):\n",
    "                        prop_val_2_list[index] = df[prop][res_id_2_index]\n",
    "\n",
    "                if (\n",
    "                        aa_1 in list(aa_dict.keys())\n",
    "                    and aa_2 in list(aa_dict.keys())\n",
    "                    and (not [domain_res_id_1, domain_res_id_2] in repeat_pairs_list)\n",
    "                    and (not [domain_res_id_2, domain_res_id_1] in repeat_pairs_list)\n",
    "                ):  # Each amino acid pair is counted once.\n",
    "                    repeat_pairs_list.append([domain_res_id_1, domain_res_id_2])\n",
    "                    repeat_pairs_list.append([domain_res_id_2, domain_res_id_1])\n",
    "\n",
    "                    neighbouring_pairs_list.append('{}_{}'.format(aa_1, aa_2))\n",
    "                    \n",
    "                    if args:\n",
    "                        for index, prop in enumerate(props):\n",
    "                            prop_val_1 = prop_val_1_list[index]\n",
    "                            prop_val_2 = prop_val_2_list[index]\n",
    "                            # Must include domain id in key to ensure it is unique\n",
    "                            props_dict[prop]['{}_{}_{}_{}'.format(domain_res_id_1, domain_res_id_2, aa_1, aa_2)] = [\n",
    "                                prop_val_1, prop_val_2\n",
    "                            ]\n",
    "                            props_dict[prop]['{}_{}_{}_{}'.format(domain_res_id_2, domain_res_id_1, aa_2, aa_1)] = [\n",
    "                                prop_val_2, prop_val_1\n",
    "                            ]\n",
    "    if args:\n",
    "        return neighbouring_pairs_list, props_dict\n",
    "    else:\n",
    "        return neighbouring_pairs_list\n",
    "\n",
    "\n",
    "def calc_aa_pair_propensities(neighbouring_pairs_list, aa_dict):\n",
    "    \"\"\"\n",
    "    Calculates propensities of amino acids at a particular location to interact with one another\n",
    "    Input: list of interacting amino acid pairs output from gen_neighbouring_pairs_list, and dictionary of amino\n",
    "           acid abbreviations\n",
    "    Returns: dataframe of propensity values, plus dataframes of the frequencies and normalised frequencies (since\n",
    "             extreme propensity values can result from low counts)\n",
    "    \"\"\"\n",
    "    # Each amino acid pair is counted in both orientations. (Note this is because positions 1 and 2 must be\n",
    "    # treated independently (position 1 = object, position 2 = property of object) in the propensity calculations,\n",
    "    # whereas these pairs do not have such an associated order and so must be listed in both orientations. See\n",
    "    # lab notes for further details.)\n",
    "    neighbouring_pairs_list = [['{}_{}'.format(aa_pair[0:1], aa_pair[-1:]), '{}_{}'.format(aa_pair[-1:], aa_pair[0:1])]\n",
    "                               for aa_pair in neighbouring_pairs_list]\n",
    "    neighbouring_pairs_list = [aa_pair for aa_pair_list in neighbouring_pairs_list for aa_pair in aa_pair_list]\n",
    "\n",
    "    # Calculates propensity values\n",
    "    all_pairs_count = len(neighbouring_pairs_list)\n",
    "    temp_lists = {}\n",
    "\n",
    "    for aa_1 in list(aa_dict.keys()):\n",
    "        temp_lists['{}_propensity_list'.format(aa_1)] = ['']*len(list(aa_dict.keys()))\n",
    "        temp_lists['{}_frequency_list'.format(aa_1)] = ['']*len(list(aa_dict.keys()))\n",
    "        temp_lists['{}_normed_frequencies_list'.format(aa_1)] = ['']*len(list(aa_dict.keys()))\n",
    "\n",
    "        # Calculates propensity for aa_1 to interact with aa_2 relative to all other amino acid possibilities\n",
    "        # (= (aa_1_aa_2_count / aa_1_count) / (aa_2_count / all_aa_count)). \n",
    "        for aa_2_index, aa_2 in enumerate(list(aa_dict.keys())):\n",
    "            aa_1_count = 0\n",
    "            aa_2_count = 0\n",
    "            aa_1_aa_2_count = 0\n",
    "\n",
    "            for aa_pair in neighbouring_pairs_list:\n",
    "                if aa_1 == aa_pair[0:1]:\n",
    "                    aa_1_count += 1\n",
    "                if aa_2 == aa_pair[-1:]:\n",
    "                    aa_2_count += 1\n",
    "                if aa_1 == aa_pair[0:1] and aa_2 == aa_pair[-1:]:\n",
    "                    aa_1_aa_2_count += 1\n",
    "\n",
    "            if min([all_pairs_count, aa_1_count, aa_2_count, aa_1_aa_2_count]) > 0:\n",
    "                aa_1_aa_2_frequency = copy.deepcopy(aa_1_aa_2_count)\n",
    "                temp_lists['{}_frequency_list'.format(aa_1)][aa_2_index] = aa_1_aa_2_frequency\n",
    "\n",
    "                aa_1_aa_2_normed_frequencies = aa_1_aa_2_count / aa_1_count\n",
    "                temp_lists['{}_normed_frequencies_list'.format(aa_1)][aa_2_index] = aa_1_aa_2_normed_frequencies\n",
    "\n",
    "                aa_1_aa_2_propensity = ((aa_1_aa_2_count / aa_1_count)\n",
    "                                        / (aa_2_count / all_pairs_count))\n",
    "                temp_lists['{}_propensity_list'.format(aa_1)][aa_2_index] = aa_1_aa_2_propensity\n",
    "            else:\n",
    "                temp_lists['{}_frequency_list'.format(aa_1)][aa_2_index] = np.nan\n",
    "                temp_lists['{}_normed_frequencies_list'.format(aa_1)][aa_2_index] = np.nan\n",
    "                temp_lists['{}_propensity_list'.format(aa_1)][aa_2_index] = np.nan\n",
    "\n",
    "    # The propensity for aa_1 to interact with aa_2 should equal the propensity for aa_2 to interact with aa_1\n",
    "    for aa_1_index, aa_1 in enumerate(list(aa_dict.keys())):\n",
    "        for aa_2_index, aa_2 in enumerate(list(aa_dict.keys())):\n",
    "            propensity_12 = temp_lists['{}_propensity_list'.format(aa_1)][aa_2_index]\n",
    "            propensity_21 = temp_lists['{}_propensity_list'.format(aa_2)][aa_1_index]\n",
    "\n",
    "            if not np.isnan(propensity_12) and not np.isnan(propensity_21):\n",
    "                if propensity_12 - propensity_21 > 0.0001:\n",
    "                    sys.exit('Error with propensity calculation: {}{} ({}) != {}{} ({})'.format(\n",
    "                        aa_1, aa_2, propensity_12, aa_2, aa_1, propensity_21\n",
    "                    ))\n",
    "\n",
    "    df_propensity_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    df_frequency_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    df_normed_frequencies_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    # FASTA label on heatmap refers to aa_2 (although propensity and frequency heatmaps will be symmetric about\n",
    "    # their central axes)\n",
    "    for aa_1 in list(aa_dict.keys()):\n",
    "        df_propensity_dict[aa_1] = temp_lists['{}_propensity_list'.format(aa_1)]\n",
    "        df_frequency_dict[aa_1] = temp_lists['{}_frequency_list'.format(aa_1)]\n",
    "        df_normed_frequencies_dict[aa_1] = temp_lists['{}_normed_frequencies_list'.format(aa_1)]\n",
    "\n",
    "    propensity_df = pd.DataFrame(df_propensity_dict)\n",
    "    frequency_df = pd.DataFrame(df_frequency_dict)\n",
    "    normed_frequencies_df = pd.DataFrame(df_normed_frequencies_dict)\n",
    "\n",
    "    return propensity_df, frequency_df, normed_frequencies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_voronoi_points(df, cont_prop_1, cont_prop_2, min_cluster_size=25):\n",
    "    \"\"\"\n",
    "    Calculates cluster centres for discretisation of 2D property space.\n",
    "    Input: dataframe of barrel / sandwich properties, first (continuous) property of interest (specified via the\n",
    "           name of the correspoing column in the input dataframe), second (continuous) property of interest\n",
    "           (specified via the name of the correspoing column in the input dataframe), and the minimum number of\n",
    "           data points to be included in a cluster (default 25)\n",
    "    Returns: numpy array of cluster coordinates, plus dataframe of cluster properties\n",
    "    \"\"\"\n",
    "    df = df[  (~df[cont_prop_1].isin(['', 'NaN', 'nan', np.nan]))\n",
    "            & (~df[cont_prop_2].isin(['', 'NaN', 'nan', np.nan]))]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    prop_array = []\n",
    "    for row in range(df.shape[0]):\n",
    "        prop_array.append([df[cont_prop_1][row], df[cont_prop_2][row]])\n",
    "    prop_array = np.array(prop_array)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=200).fit(prop_array)\n",
    "\n",
    "    if kmeans.n_iter_ >= 300:\n",
    "        sys.exit('Clustering failed to converge')\n",
    "\n",
    "    else:\n",
    "        cluster_coords = kmeans.cluster_centers_\n",
    "\n",
    "        cluster_sizes = np.unique(kmeans.labels_, return_counts=True)\n",
    "        cluster_sizes = cluster_sizes[1]\n",
    "\n",
    "        smallest_cluster_size = cluster_sizes.min()\n",
    "        while smallest_cluster_size < min_cluster_size:\n",
    "            smallest_cluster_index = np.abs(cluster_sizes).argmin()\n",
    "            smallest_cluster_coords = cluster_coords[smallest_cluster_index]\n",
    "\n",
    "            distances = np.sqrt(np.sum(np.square(cluster_coords-smallest_cluster_coords), axis=1))\n",
    "            distances[smallest_cluster_index] = 1e10\n",
    "            closest_cluster_index = np.abs(distances).argmin()\n",
    "            closest_cluster_size = cluster_sizes[closest_cluster_index]\n",
    "\n",
    "            cluster_sizes[closest_cluster_index] = closest_cluster_size + smallest_cluster_size\n",
    "            cluster_sizes = np.delete(cluster_sizes, smallest_cluster_index)\n",
    "            cluster_coords = np.delete(cluster_coords, smallest_cluster_index, axis=0)\n",
    "\n",
    "            smallest_cluster_size = cluster_sizes.min()\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.scatter(prop_array[:,0], prop_array[:,1], alpha=0.1)\n",
    "        plt.scatter(cluster_coords[:,0], cluster_coords[:,1], color='k')\n",
    "        plt.show()\n",
    "\n",
    "        cluster_df = pd.DataFrame({'Cluster size': cluster_sizes,\n",
    "                                   '{}'.format(cont_prop_1): cluster_coords[:,0],\n",
    "                                   '{}'.format(cont_prop_2): cluster_coords[:,1]})\n",
    "\n",
    "        return cluster_coords, cluster_df\n",
    "\n",
    "\n",
    "def calc_discrete_2d_indv_aa_propensities(df, cont_prop_1, cont_prop_2, aa_dict, cluster_coords):\n",
    "    \"\"\"\n",
    "    Calculates amino acid propensity values for bins in 2D property space.\n",
    "    Input: dataframe of barrel / sandwich properties, first (continuous) property of interest (specified via the\n",
    "           name of the corresponding column in the input dataframe), second (continuous) property of interest\n",
    "           (specified via the name of the corresponding column in the input dataframe), dictionary of amino acid\n",
    "           abbreviations, and coordinates of cluster centres\n",
    "    Returns: dataframe of propensity values, plus dataframes of frequency and normalised frequency values (since\n",
    "             propensity values can be skewed by very small sample sizes)\n",
    "    \"\"\"\n",
    "    df = df[  (~df[cont_prop_1].isin(['', 'NaN', 'nan', np.nan]))\n",
    "            & (~df[cont_prop_2].isin(['', 'NaN', 'nan', np.nan]))]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    propensity_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    frequency_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    normed_frequencies_dict = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "    voronoi_class_dict = OrderedDict()\n",
    "\n",
    "    for voronoi_index in range(cluster_coords.shape[0]):\n",
    "        voronoi_class_dict[voronoi_index] = [0]*(len(aa_dict)+1)\n",
    "        propensity_dict[voronoi_index] = [np.nan]*len(aa_dict)\n",
    "        frequency_dict[voronoi_index] = [np.nan]*len(aa_dict)\n",
    "        normed_frequencies_dict[voronoi_index] = [np.nan]*len(aa_dict)\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        fasta = df['fasta_seq'][row]\n",
    "        aa_index = list(aa_dict.keys()).index(fasta)\n",
    "\n",
    "        val_1 = df[cont_prop_1][row]\n",
    "        val_2 = df[cont_prop_2][row]\n",
    "        prop_vals = np.array([val_1, val_2])\n",
    "\n",
    "        distances = np.sqrt(np.sum(np.square(cluster_coords-prop_vals), axis=1))\n",
    "        voronoi_index = np.abs(distances).argmin()\n",
    "        voronoi_class_dict[voronoi_index][aa_index] += 1\n",
    "        voronoi_class_dict[voronoi_index][-1] +=1\n",
    "\n",
    "    for voronoi_index in list(voronoi_class_dict.keys()):\n",
    "        for aa_index, aa in enumerate(list(aa_dict.keys())):\n",
    "            class_aa_count = voronoi_class_dict[voronoi_index][aa_index]\n",
    "            class_all_aas_count = voronoi_class_dict[voronoi_index][-1]\n",
    "\n",
    "            total_aa_count = 0\n",
    "            for voronoi_class_list in list(voronoi_class_dict.values()):\n",
    "                total_aa_count += voronoi_class_list[aa_index]\n",
    "\n",
    "            try:\n",
    "                frequency_dict[voronoi_index][aa_index] = copy.deepcopy(class_aa_count)\n",
    "                normed_frequencies_dict[voronoi_index][aa_index] = class_aa_count / class_all_aas_count\n",
    "                propensity_dict[voronoi_index][aa_index] = (  (class_aa_count / class_all_aas_count)\n",
    "                                                            / (total_aa_count / df.shape[0]))\n",
    "            except ZeroDivisionError:\n",
    "                pass\n",
    "\n",
    "    propensity_df = pd.DataFrame(propensity_dict)\n",
    "    frequency_df = pd.DataFrame(frequency_dict)\n",
    "    normed_frequencies_df = pd.DataFrame(normed_frequencies_dict)\n",
    "\n",
    "    return propensity_df, frequency_df, normed_frequencies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_discrete_propensities(df, prop, aa_dict, num_bootstrap_samples, propensity_calc_func, *args):\n",
    "    \"\"\"\n",
    "    Calculates 95% confidence limits about propensity values calculated for discrete categorical features\n",
    "    Input: dataframe of barrel / sandwich properties, name(s) of the feature(s) of interest (specified via a\n",
    "           name / list of names of the corresponding column(s) in the input dataframe, dictionary of amino\n",
    "           acid abbreviations, the number of bootstrap samples to collect, the name of the propensity\n",
    "           calculation function (calc_indv_property_propensities, calc_combined_property_propensities,\n",
    "           calc_aa_pair_propensities, or calc_discrete_2d_indv_aa_propensities), and the minimum number of data\n",
    "           points in each cluster (if calculating propensities for bins in 2D property space, e.g. phi vs. psi)\n",
    "    Returns: dictionary of bootstrapped propensity values, plus dictionaries of the bootstrapped frequencies\n",
    "             and normalised frequencies (since extreme propensity values can result from low counts)\n",
    "    \"\"\"\n",
    "    if propensity_calc_func == calc_indv_property_propensities:\n",
    "        prop_vals = list(set(df[prop].tolist()))\n",
    "        prop_vals = remove_nan(prop_vals)\n",
    "\n",
    "    elif propensity_calc_func == calc_combined_property_propensities:\n",
    "        prop_vals = []\n",
    "        for sub_prop in prop:\n",
    "            vals = list(set(df[sub_prop].tolist()))\n",
    "            vals = remove_nan(vals)\n",
    "            prop_vals.append(vals)\n",
    "        prop_vals = list(itertools.product(*prop_vals))\n",
    "        prop_vals = ['_'.join(tup) for tup in prop_vals]\n",
    "\n",
    "    elif propensity_calc_func == calc_aa_pair_propensities:\n",
    "        prop_vals = list(aa_dict.keys())\n",
    "        neighbouring_pairs_list = gen_neighbouring_pairs_list(df, prop, aa_dict)\n",
    "\n",
    "    elif propensity_calc_func == calc_discrete_2d_indv_aa_propensities:\n",
    "        cluster_coords, cluster_df = calc_voronoi_points(df, prop[0], prop[1], args)\n",
    "        prop_vals = [num for num in range(cluster_coords.shape[0])]\n",
    "\n",
    "    aa_list = list(aa_dict.keys())\n",
    "\n",
    "    bootstrap_propensities_dict = OrderedDict({'FASTA': aa_list})\n",
    "    bootstrap_frequencies_dict = OrderedDict({'FASTA': aa_list})\n",
    "    bootstrap_normed_frequencies_dict = OrderedDict({'FASTA': aa_list})\n",
    "\n",
    "    for prop_val in prop_vals:\n",
    "        bootstrap_propensities_dict[prop_val] = [([np.nan]*num_bootstrap_samples) for i in range(len(aa_list))]\n",
    "        bootstrap_frequencies_dict[prop_val] = [([np.nan]*num_bootstrap_samples) for i in range(len(aa_list))]\n",
    "        bootstrap_normed_frequencies_dict[prop_val] = [([np.nan]*num_bootstrap_samples) for i in range(len(aa_list))]\n",
    "\n",
    "    for num_1 in range(num_bootstrap_samples):\n",
    "        if propensity_calc_func in [calc_indv_property_propensities, calc_combined_property_propensities,\n",
    "                                    calc_discrete_2d_indv_aa_propensities]:\n",
    "            # Samples input dataframe with replacement\n",
    "            indices = []\n",
    "            for num_2 in range(df.shape[0]):\n",
    "                random_num = random.randint(0, (df.shape[0]-1))\n",
    "                indices.append(random_num)\n",
    "            new_df = df.iloc[indices]\n",
    "            new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "            if propensity_calc_func in [calc_indv_property_propensities, calc_combined_property_propensities]:\n",
    "                propensity_df, frequency_df, normed_frequencies_df = propensity_calc_func(\n",
    "                    new_df, prop, aa_dict\n",
    "                )\n",
    "            elif propensity_calc_func == calc_discrete_2d_indv_aa_propensities:\n",
    "                propensity_df, frequency_df, normed_frequencies_df = propensity_calc_func(\n",
    "                    new_df, prop[0], prop[1], aa_dict, cluster_coords\n",
    "                )\n",
    "\n",
    "        elif propensity_calc_func == calc_aa_pair_propensities:\n",
    "            # Samples neighbouring_pairs_list with replacement\n",
    "            resampled_pairs_list = random.choices(neighbouring_pairs_list, k=len(neighbouring_pairs_list))\n",
    "            \n",
    "            propensity_df, frequency_df, normed_frequencies_df = propensity_calc_func(\n",
    "                resampled_pairs_list, aa_dict\n",
    "            )\n",
    "\n",
    "        for prop_val in prop_vals:\n",
    "            for index, num_3 in enumerate(propensity_df[prop_val].tolist()):\n",
    "                bootstrap_propensities_dict[prop_val][index][num_1] = propensity_df[prop_val][index]\n",
    "                bootstrap_frequencies_dict[prop_val][index][num_1] = frequency_df[prop_val][index]\n",
    "                bootstrap_normed_frequencies_dict[prop_val][index][num_1] = normed_frequencies_df[prop_val][index]\n",
    "\n",
    "    return bootstrap_propensities_dict, bootstrap_frequencies_dict, bootstrap_normed_frequencies_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_graphs(df, propensity_or_frequency):\n",
    "    \"\"\"\n",
    "    Plots a bar graph of property / propensity of interest vs. amino acid identity\n",
    "    Input: dataframe of barrel / sandwich properties, and string defining whether the input dataframe contains\n",
    "           propensity, frequency or normalised frequency values\n",
    "           (specified via the name of the corresponding column in the input dataframe)\n",
    "    \"\"\"\n",
    "    reshaped_df = pd.melt(df, id_vars='FASTA', var_name='Property', value_name=propensity_or_frequency)\n",
    "    reshaped_df = reshaped_df.dropna()\n",
    "    reshaped_df = reshaped_df.reset_index(drop=True)\n",
    "\n",
    "    plt.clf()\n",
    "    sns.catplot(x='FASTA', y=propensity_or_frequency, hue='Property', data=reshaped_df, kind='bar', height=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_95_conf_intervals(bootstrap_propensity_dict, propensity_or_frequency, middle=False):\n",
    "    \"\"\"\n",
    "    Calculates 95% confidence intervals from bootstrapped sample.\n",
    "    Input: dictionary of bootstrapped propensity values, and string defining whether the input dataframe contains\n",
    "           propensity, frequency or normalised frequency values\n",
    "    Returns: dictionary of lower percentile propensity values, dictionary of upper percentile propensity values\n",
    "    \"\"\"\n",
    "    aa_list = bootstrap_propensity_dict['FASTA']\n",
    "    \n",
    "    lower_percentile_dict = OrderedDict({'FASTA': aa_list})\n",
    "    upper_percentile_dict = OrderedDict({'FASTA': aa_list})\n",
    "    if middle is True:\n",
    "        middle_percentile_dict = OrderedDict({'FASTA': aa_list})\n",
    "\n",
    "    for prop_val in list(bootstrap_propensity_dict.keys()):\n",
    "        if prop_val != 'FASTA':\n",
    "            lower_percentile_dict[prop_val] = [np.nan]*len(aa_list)\n",
    "            upper_percentile_dict[prop_val] = [np.nan]*len(aa_list)\n",
    "            if middle is True:\n",
    "                middle_percentile_dict[prop_val] = [np.nan]*len(aa_list)\n",
    "\n",
    "            for index, propensity_list in enumerate(bootstrap_propensity_dict[prop_val]):\n",
    "                propensity_list = [val for val in propensity_list if not np.isnan(val)]\n",
    "                if propensity_list:\n",
    "                    lower_percentile = np.percentile(propensity_list, 2.5)\n",
    "                    upper_percentile = np.percentile(propensity_list, 97.5) \n",
    "                    middle_percentile = np.percentile(propensity_list, 50)\n",
    "                else:\n",
    "                    lower_percentile = np.nan\n",
    "                    upper_percentile = np.nan\n",
    "                    middle_percentile = np.nan\n",
    "\n",
    "                lower_percentile_dict[prop_val][index] = lower_percentile\n",
    "                upper_percentile_dict[prop_val][index] = upper_percentile\n",
    "                if middle is True:\n",
    "                    middle_percentile_dict[prop_val][index] = middle_percentile\n",
    "\n",
    "    if middle is False:\n",
    "        return lower_percentile_dict, upper_percentile_dict\n",
    "    if middle is True:\n",
    "        return lower_percentile_dict, upper_percentile_dict, middle_percentile_dict\n",
    "\n",
    "\n",
    "def plot_bar_graphs_with_conf_limits(bootstrap_df, lower_percentile_dict, upper_percentile_dict,\n",
    "                                     propensity_or_frequency):\n",
    "    \"\"\"\n",
    "    Plots a bar graph of property / propensity of interest vs. amino acid identity with bootstrapped 95%\n",
    "    confidence limits\n",
    "    Input: dataframe of initial propensity values, dataframe of bootstrapped lower percentile values, dataframe\n",
    "           of bootstrapped upper percentile values, and string defining whether the input dataframe contains\n",
    "           propensity, frequency or normalised frequency values\n",
    "    \"\"\"\n",
    "    reshaped_df = pd.melt(bootstrap_df, id_vars='FASTA', var_name='Property', value_name=propensity_or_frequency)\n",
    "    reshaped_df = reshaped_df.dropna()\n",
    "    reshaped_df = reshaped_df.reset_index(drop=True)\n",
    "\n",
    "    lower_percentile_df = pd.DataFrame(lower_percentile_dict)\n",
    "    lower_percentile_df = pd.melt(lower_percentile_df, id_vars='FASTA', var_name='Property',\n",
    "                                  value_name=propensity_or_frequency)\n",
    "    upper_percentile_df = pd.DataFrame(upper_percentile_dict)\n",
    "    upper_percentile_df = pd.melt(upper_percentile_df, id_vars='FASTA', var_name='Property',\n",
    "                                  value_name=propensity_or_frequency)\n",
    "\n",
    "    # Plots bar graph with confidence limits\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.barplot(x='FASTA', y=propensity_or_frequency, hue='Property', data=reshaped_df)\n",
    "    sns.stripplot(x='FASTA', y=propensity_or_frequency, hue='Property', data=lower_percentile_df,\n",
    "                  jitter=False, dodge=True, palette='dark')\n",
    "    sns.stripplot(x='FASTA', y=propensity_or_frequency, hue='Property', data=upper_percentile_df,\n",
    "                  jitter=False, dodge=True, palette='dark')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conf_limits(prop_list, aa_list, lower_percentile_dict, df, upper_percentile_dict):\n",
    "    \"\"\"\n",
    "    Prints confidence limits about discrete property propensity values for each aa\n",
    "    Input: list of discrete properties, list of amino acids, dictionary of lower percentile values, dataframe of\n",
    "           propensity (or frequency or normalised frequency) values, dictionary of upper percentile values\n",
    "    \"\"\"\n",
    "    for prop in prop_list:\n",
    "        for index, aa in enumerate(aa_list):\n",
    "            print(aa, prop)\n",
    "            print('[{}, {}, {}]'.format(\n",
    "                lower_percentile_dict[prop][index], df[prop][index], upper_percentile_dict[prop][index]\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_bootstrap_propensities(df, prop, aa_dict, bootstrap_samples_list, propensity_calc_func, propensity_df,\n",
    "                                   frequency_df, normed_frequencies_df, *args):\n",
    "    \"\"\"\n",
    "    Calculates 95% confidence limits about propensity, frequency and normalised frequency values calculated for\n",
    "    discrete categorical features whilst varying the size of the bootstrap population (to determine the minimum\n",
    "    number of bootstrap samples required to obtain an accurate estimate of the confidence limits)\n",
    "    Input: dataframe of barrel / sandwich properties, name(s) of the feature(s) of interest (specified via a\n",
    "           name / list of names of the corresponding column(s) in the input dataframe), dictionary of amino\n",
    "           acid abbreviations, list of number of bootstrap samples to use in the confidence limit calculation,\n",
    "           name of the propensity calculation function (calc_indv_property_propensities,\n",
    "           calc_combined_property_propensities, calc_aa_pair_propensities, or calc_discrete_2d_indv_aa_propensities),\n",
    "           dataframe of (non-bootstrapped) propensity values, dataframe of (non-bootstrapped) frequency values,\n",
    "           dataframe of (non-bootstrapped) normalised frequency values, and minimum number of data points in each\n",
    "           cluster (calc_discrete_2d_indv_aa_propensities)\n",
    "    Returns: dictionaries of propensity, frequency and normalised frequency values vs. number of bootstrap samples\n",
    "    \"\"\"\n",
    "    dfs = {'Propensity': propensity_df,\n",
    "           'Frequency': frequency_df,\n",
    "           'Normalised frequency': normed_frequencies_df}\n",
    "\n",
    "    iterated_dicts = {'Propensity': OrderedDict(),\n",
    "                      'Frequency': OrderedDict(),\n",
    "                      'Normalised frequency': OrderedDict()}\n",
    "\n",
    "    for num in bootstrap_samples_list:\n",
    "        print(num)\n",
    "        (bootstrap_propensities_dict, bootstrap_frequencies_dict, bootstrap_normed_frequencies_dict\n",
    "        ) = bootstrap_discrete_propensities(df, prop, aa_dict, num, propensity_calc_func, args)\n",
    "        bootstrapped_dicts = {'Propensity': bootstrap_propensities_dict,\n",
    "                              'Frequency': bootstrap_frequencies_dict,\n",
    "                              'Normalised frequency': bootstrap_normed_frequencies_dict}\n",
    "\n",
    "        for output_type, iterated_dict in iterated_dicts.items():\n",
    "            bootstrap_dict = bootstrapped_dicts[output_type]\n",
    "            \n",
    "            if propensity_calc_func in [calc_indv_property_propensities, calc_combined_property_propensities,\n",
    "                                        calc_aa_pair_propensities]:\n",
    "                lower_percentile, upper_percentile = gen_95_conf_intervals(\n",
    "                    bootstrap_dict, output_type\n",
    "                )\n",
    "            elif propensity_calc_func == calc_discrete_2d_indv_aa_propensities:\n",
    "                lower_percentile, upper_percentile, middle_percentile = gen_95_conf_intervals(\n",
    "                    bootstrap_dict, output_type, middle=True\n",
    "                )\n",
    "            iterated_dict[num] = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "\n",
    "            for prop_val in list(bootstrap_dict.keys()):\n",
    "                if prop_val != 'FASTA':\n",
    "                    iterated_dict[num][prop_val] = ['']*len(list(aa_dict.keys()))\n",
    "\n",
    "                    if propensity_calc_func in [calc_indv_property_propensities, calc_combined_property_propensities,\n",
    "                                                calc_aa_pair_propensities]:\n",
    "                        for index, aa in enumerate(list(aa_dict.keys())):\n",
    "                            iterated_dict[num][prop_val][index] = [\n",
    "                                lower_percentile[prop_val][index], dfs[output_type][prop_val][index],\n",
    "                                upper_percentile[prop_val][index],\n",
    "                            ]\n",
    "                    elif propensity_calc_func == calc_discrete_2d_indv_aa_propensities:\n",
    "                        for index, aa in enumerate(list(aa_dict.keys())):\n",
    "                            iterated_dict[num][prop_val][index] = [\n",
    "                                lower_percentile[prop_val][index], middle_percentile[prop_val][index],\n",
    "                                upper_percentile[prop_val][index],\n",
    "                            ]\n",
    "\n",
    "    for output_type, iterated_dict in iterated_dicts.items():\n",
    "        for index, aa in enumerate(list(aa_dict.keys())):\n",
    "            print(aa)\n",
    "            x_vals = []\n",
    "            y_vals = []\n",
    "            hue_vals = []\n",
    "\n",
    "            for prop_val in list(iterated_dict[min(bootstrap_samples_list)].keys()):\n",
    "                if prop_val != 'FASTA':\n",
    "                    for num in bootstrap_samples_list:\n",
    "                        percentiles = iterated_dict[num][prop_val][index]\n",
    "                        x_vals += [num]*3\n",
    "                        y_vals += [percentiles[0], percentiles[1], percentiles[2]]\n",
    "                        hue_vals += [prop_val]*3\n",
    "            \n",
    "            melted_df = pd.DataFrame({'Bootstrap samples': x_vals,\n",
    "                                      '{}'.format(output_type): y_vals,\n",
    "                                      'Property': hue_vals})\n",
    "            plt.clf()\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            sns.swarmplot(x='Bootstrap samples', y=output_type, hue='Property', data=melted_df)\n",
    "            plt.show()\n",
    "\n",
    "    return iterated_dicts[0], iterated_dicts[1], iterated_dicts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heat_map(df):\n",
    "    \"\"\"\n",
    "    Plots a heat map.\n",
    "    Input: dataframe of propensity / count data of property of interest vs. amino acid identity (which must be in\n",
    "           a column labelled 'FASTA')\n",
    "    \"\"\"\n",
    "    df = df.set_index('FASTA', drop=True)  # \"FASTA\" label on y-axis of heat map refers to amino acid 2\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.heatmap(df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aa_kdes(df, cont_props, indv_or_comp, aa_dict):\n",
    "    \"\"\"\n",
    "    Plots kernel density estimate of the distribution of each amino acid of interest vs. 1 / 2 continuous\n",
    "    property/ies of interest (typically z-coordinate)\n",
    "    Input: dataframe of barrel / sandwich properties, name of continuous property of interest (specified via a list\n",
    "           of the name(s) of the corresponding column in the input dataframe), whether to plot the distribution of\n",
    "           the amino acid alone ('individual') or whether to also plot the distribution of all amino acids\n",
    "           ('comparison'), and dictionary of amino acid abbreviations\n",
    "    \"\"\"\n",
    "    for prop in cont_props:\n",
    "        df = df[~df[prop].isin(['', 'NaN', 'nan', np.nan])]\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    for aa in list(aa_dict.keys()):\n",
    "        aa_df = df[df['fasta_seq'] == aa]\n",
    "        aa_df = aa_df.reset_index(drop=True)\n",
    "\n",
    "        num_prop_vals = []\n",
    "        for prop in cont_props:\n",
    "            num_prop_vals.append(len(df[prop]))\n",
    "            num_prop_vals.append(len(aa_df[prop]))\n",
    "\n",
    "        if min(num_prop_vals) >= 10:\n",
    "            print(aa)\n",
    "\n",
    "            plt.clf()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            if 'z_coords' in cont_props:\n",
    "                axes = plt.gca()\n",
    "\n",
    "            if len(cont_props) == 1:\n",
    "                if indv_or_comp == 'comparison':\n",
    "                    sns.distplot(df[cont_props[0]], hist=False, kde_kws={'bw':'scott'})\n",
    "                sns.distplot(aa_df[cont_props[0]], hist=False, rug=True, kde_kws={'bw':'scott'},\n",
    "                             rug_kws={'alpha': 0.1})\n",
    "            elif len(cont_props) == 2:\n",
    "                if indv_or_comp == 'comparison':\n",
    "                    sns.kdeplot(data=df[cont_props[0]], data2=df[cont_props[1]], bw='scott', shade=True,\n",
    "                                shade_lowest=False, cbar=True)\n",
    "                sns.kdeplot(data=aa_df[cont_props[0]], data2=aa_df[cont_props[1]], bw='scott', shade=False, cbar=True)\n",
    "            else:\n",
    "                return('Too many properties specified')\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_indv_aa_propensities(df, cont_prop, aa_dict):\n",
    "    \"\"\"\n",
    "    Plots propensity of each amino acid of interest vs. a continuous property of interest (typically z-coordinate)\n",
    "    Input: dataframe of barrel / sandwich properties, name of continuous property of interest (specified via the\n",
    "           name of the corresponding column in the input dataframe), and dictionary of amino acid abbreviations\n",
    "    \"\"\"\n",
    "    df = df[~df[cont_prop].isin(['', 'NaN', 'nan', np.nan])]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    propensities_dict = OrderedDict()\n",
    "\n",
    "    for aa in list(aa_dict.keys()):\n",
    "        aa_df = df[df['fasta_seq'] == aa]\n",
    "        aa_df = aa_df.reset_index(drop=True)\n",
    "\n",
    "        if (\n",
    "            min([df.shape[0], aa_df.shape[0]]) >= 10\n",
    "        ):\n",
    "            print(aa)\n",
    "\n",
    "            plt.clf()\n",
    "            overall_data = np.asarray(df[cont_prop].tolist())\n",
    "            overall_data = overall_data.astype(np.float64)\n",
    "            x_values_overall, y_values_overall = sns.distributions._statsmodels_univariate_kde(\n",
    "                data=overall_data, kernel='gau', bw='scott', gridsize=100, cut=3, clip=(-np.inf, np.inf),\n",
    "                cumulative=False\n",
    "            )\n",
    "\n",
    "            # Determines range over which interpolation is carried out\n",
    "            min_x_vals = [min(df[cont_prop]), min(aa_df[cont_prop])]\n",
    "            max_x_vals = [max(df[cont_prop]), max(aa_df[cont_prop])]\n",
    "            x_range = [max(min_x_vals), min(max_x_vals)]\n",
    "\n",
    "            plt.clf()\n",
    "            indv_data = np.asarray(aa_df[cont_prop].tolist())\n",
    "            indv_data = indv_data.astype(np.float64)\n",
    "            x_values_indv, y_values_indv = sns.distributions._statsmodels_univariate_kde(\n",
    "                data=indv_data, kernel='gau', bw='scott', gridsize=100, cut=3, clip=(-np.inf, np.inf),\n",
    "                cumulative=False\n",
    "            )\n",
    "\n",
    "            x_values_indv_copy = list(copy.deepcopy(x_values_indv))\n",
    "            propensities = ['']*len(x_values_indv)\n",
    "\n",
    "            # Interpolate overall KDE since it has been calculated from more data points\n",
    "            for index_1, value_1 in np.ndenumerate(x_values_indv):\n",
    "                index_1 = index_1[0]\n",
    "                x_indv = x_values_indv[index_1]\n",
    "                y_indv = y_values_indv[index_1]\n",
    "\n",
    "                if (   x_indv < x_range[0]\n",
    "                    or x_indv > x_range[-1]\n",
    "                ):\n",
    "                    x_values_indv_copy[index_1] = ''\n",
    "\n",
    "                else:\n",
    "                    interpolate_x_indices = []\n",
    "                    for index_2, value_2 in np.ndenumerate(x_values_overall):\n",
    "                        index_2 = index_2[0]\n",
    "                        if x_values_overall[index_2] == x_indv:\n",
    "                            if index_2 < (len(x_values_overall)-1):\n",
    "                                interpolate_x_indices = [index_2, index_2+1]\n",
    "                            else:\n",
    "                                interpolate_x_indices = [index_2-1, index_2]\n",
    "                            break\n",
    "                        elif (    x_values_overall[index_2] < x_indv\n",
    "                            and x_values_overall[index_2+1] > x_indv\n",
    "                        ):\n",
    "                            interpolate_x_indices = [index_2, index_2+1]\n",
    "                            break\n",
    "\n",
    "                    x_1 = x_values_overall[interpolate_x_indices[0]]\n",
    "                    x_2 = x_values_overall[interpolate_x_indices[1]]\n",
    "                    y_1 = y_values_overall[interpolate_x_indices[0]]\n",
    "                    y_2 = y_values_overall[interpolate_x_indices[1]]\n",
    "\n",
    "                    y_1_weight = abs(x_2 - x_indv) / abs(x_2 - x_1)\n",
    "                    y_2_weight = abs(x_indv - x_1) / abs(x_2 - x_1)\n",
    "\n",
    "                    y_overall = (y_1*y_1_weight) + (y_2*y_2_weight)\n",
    "\n",
    "                    propensity = y_indv / y_overall\n",
    "                    propensities[index_1] = propensity\n",
    "\n",
    "            x_values_indv_copy = [x for x in x_values_indv_copy if x != '']\n",
    "            propensities = [y for y in propensities if y != '']\n",
    "\n",
    "            # Updates dictionary of amino acid propensities\n",
    "            propensities_dict[aa] = np.array([x_values_indv_copy,\n",
    "                                              propensities])\n",
    "\n",
    "            plt.clf()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            axes = plt.gca()\n",
    "            plt.plot(np.array(x_values_indv_copy), np.array(propensities))\n",
    "            plt.show()\n",
    "\n",
    "    return propensities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_indv_aa_propensities(df, cont_prop_1, cont_prop_2, aa_dict, cont_prop_1_range, cont_prop_2_range):\n",
    "    \"\"\"\n",
    "    Calculates propensity of each amino acid of interest vs. two propensities of interest (typically z-coordinate)\n",
    "    Input: dataframe of barrel / sandwich properties, name of the first continuous property of interest (specified\n",
    "           via the name of the corresponding column in the input dataframe), name of the second continuous property\n",
    "           of interest (specified via the name of the corresponding column in the input dataframe), dictionary of\n",
    "           amino acid abbreviations, range of values over which to calculate propensity values for continuous\n",
    "           property 1, and range of values over which to calculate propensity values for continuous property 2\n",
    "    \"\"\"\n",
    "    df = df[  (~df[cont_prop_1].isin(['', 'NaN', 'nan', np.nan]))\n",
    "            & (~df[cont_prop_2].isin(['', 'NaN', 'nan', np.nan]))]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    propensities_dict = OrderedDict()\n",
    "\n",
    "    for aa in list(aa_dict.keys()):\n",
    "        aa_df = df[df['fasta_seq'] == aa]\n",
    "        aa_df = aa_df.reset_index(drop=True)\n",
    "\n",
    "        if min([df.shape[0], aa_df.shape[0]]) >= 10:\n",
    "            print(aa)\n",
    "\n",
    "            plt.clf()\n",
    "            overall_data_1 = np.asarray(df[cont_prop_1].tolist())\n",
    "            overall_data_1 = overall_data_1.astype(np.float64)\n",
    "            overall_data_2 = np.asarray(df[cont_prop_2].tolist())\n",
    "            overall_data_2 = overall_data_2.astype(np.float64)\n",
    "            x_values_overall, y_values_overall, z_values_overall = sns.distributions._statsmodels_bivariate_kde(\n",
    "                x=overall_data_1, y=overall_data_2, bw='scott', gridsize=100, cut=3,\n",
    "                clip=[(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "            )\n",
    "\n",
    "            plt.clf()\n",
    "            indv_data_1 = np.asarray(aa_df[cont_prop_1].tolist())\n",
    "            indv_data_1 = indv_data_1.astype(np.float64)\n",
    "            indv_data_2 = np.asarray(aa_df[cont_prop_2].tolist())\n",
    "            indv_data_2 = indv_data_2.astype(np.float64)\n",
    "            x_values_indv, y_values_indv, z_values_indv = sns.distributions._statsmodels_bivariate_kde(\n",
    "                x=indv_data_1, y=indv_data_2, bw='scott', gridsize=100, cut=3,\n",
    "                clip=[(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "            )\n",
    "\n",
    "            propensities = np.full(z_values_indv.shape, np.nan)\n",
    "            # Interpolate overall KDE since it has been calculated from more data points\n",
    "            for index_1, value_1 in np.ndenumerate(z_values_indv):\n",
    "                column = index_1[0]\n",
    "                row = index_1[1]\n",
    "\n",
    "                x_indv = x_values_indv[column][row]\n",
    "                y_indv = y_values_indv[column][row]\n",
    "                z_indv = z_values_indv[column][row]\n",
    "\n",
    "                # Finds x,y pairs in overall z distribution for interpolation\n",
    "                if (    x_indv >= cont_prop_1_range[0]\n",
    "                    and x_indv <= cont_prop_1_range[-1]\n",
    "                    and y_indv >= cont_prop_2_range[0]\n",
    "                    and y_indv <= cont_prop_2_range[-1]\n",
    "                ):\n",
    "                    interpolate_x_indices = []\n",
    "                    interpolate_y_indices = []\n",
    "\n",
    "                    x_distribution = x_values_overall[0]\n",
    "                    for index_2, value_2 in np.ndenumerate(x_distribution):\n",
    "                        index_2 = index_2[0]\n",
    "                        if x_distribution[index_2] == x_indv:\n",
    "                            if index_2 != (len(x_distribution)-1):\n",
    "                                interpolate_x_indices = [index_2, index_2+1]\n",
    "                            else:\n",
    "                                interpolate_x_indices = [index_2-1, index_2]\n",
    "                            break\n",
    "                        elif (    x_distribution[index_2] < x_indv\n",
    "                              and x_distribution[index_2+1] > x_indv\n",
    "                        ):\n",
    "                            interpolate_x_indices = [index_2, index_2+1]\n",
    "                            break\n",
    "\n",
    "                    y_distribution = np.transpose(y_values_overall)[0]\n",
    "                    for index_3, value_3 in np.ndenumerate(y_distribution):\n",
    "                        index_3 = index_3[0]\n",
    "                        if y_distribution[index_3] == y_indv:\n",
    "                            if index_3 != (len(y_distribution)-1):\n",
    "                                interpolate_y_indices = [index_3, index_3+1]\n",
    "                            else:\n",
    "                                interpolate_y_indices = [index_3-1, index_3]\n",
    "                            break\n",
    "                        elif (    y_distribution[index_3] < y_indv\n",
    "                              and y_distribution[index_3+1] > y_indv\n",
    "                        ):\n",
    "                            interpolate_y_indices = [index_3, index_3+1]\n",
    "                            break\n",
    "\n",
    "                    # Bilinear interpolation calculation\n",
    "                    x1 = x_values_overall[0][interpolate_x_indices[0]]\n",
    "                    x2 = x_values_overall[0][interpolate_x_indices[1]]\n",
    "                    y1 = y_values_overall[interpolate_y_indices[0]][0]\n",
    "                    y2 = y_values_overall[interpolate_y_indices[1]][0]\n",
    "                    z_x1y1 = z_values_overall[interpolate_y_indices[0]][interpolate_x_indices[0]]\n",
    "                    z_x2y1 = z_values_overall[interpolate_y_indices[0]][interpolate_x_indices[1]]\n",
    "                    z_x1y2 = z_values_overall[interpolate_y_indices[1]][interpolate_x_indices[0]]\n",
    "                    z_x2y2 = z_values_overall[interpolate_y_indices[1]][interpolate_x_indices[1]]\n",
    "\n",
    "                    # Interpolation in x\n",
    "                    x1_weight = abs(x2 - x_indv) / abs(x2 - x1)\n",
    "                    x2_weight = abs(x_indv - x1) / abs(x2 - x1)\n",
    "                    z_xy1 = (z_x1y1*x1_weight) + (z_x2y1*x2_weight)\n",
    "                    z_xy2 = (z_x1y2*x1_weight) + (z_x2y2*x2_weight)\n",
    "\n",
    "                    # Interpolation in y\n",
    "                    y1_weight = abs(y2 - y_indv) / abs(y2 - y1)\n",
    "                    y2_weight = abs(y_indv - y1) / abs(y2 - y1)\n",
    "                    z_overall = (z_xy1*y1_weight) + (z_xy2*y2_weight)\n",
    "\n",
    "                    # Propensity calculation\n",
    "                    propensity = z_indv / z_overall\n",
    "                    propensities[column][row] = propensity\n",
    "\n",
    "            # Plots individual pairwise KDEs used in propensity calculation\n",
    "            plt.clf()\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            contours_1 = ax.contour(x_values_overall, y_values_overall, z_values_overall, 10, cmap='Blues')\n",
    "            colourbar_1 = fig.colorbar(contours_1)\n",
    "            contours_2 = ax.contour(x_values_indv, y_values_indv, z_values_indv, 10, cmap='Oranges')\n",
    "            colourbar_2 = fig.colorbar(contours_2)\n",
    "            plt.show()\n",
    "\n",
    "            # Plots propensity KDE\n",
    "            plt.clf()\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            contours_1 = ax.contourf(x_values_indv, y_values_indv, propensities, 10, cmap='Oranges')\n",
    "            colourbar_1 = fig.colorbar(contours_1)\n",
    "            plt.show()\n",
    "            \n",
    "            # Updates dictionary of amino acid propensities\n",
    "            propensities_dict[aa] = np.array([x_values_indv,\n",
    "                                              y_values_indv,\n",
    "                                              propensities])\n",
    "\n",
    "    return propensities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_pairwise_aa_propensities(df, interaction, cont_prop, aa_dict):\n",
    "    \"\"\"\n",
    "    Calculates propensities of amino acid pairs to interact with one another at different values of a continuous\n",
    "    property of interest\n",
    "    Input: dataframe of barrel / sandwich properties, name of interaction type of interest (specified via the\n",
    "           name of the corresponding column in the input dataframe), name of continuous property of interest\n",
    "           (specified via the name of the corresponding column in the input dataframe), and dictionary of amino\n",
    "           acid abbreviations \n",
    "    \"\"\"\n",
    "    df = df[~df[cont_prop].isin(['', 'NaN', 'nan', np.nan])]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    propensities_dict = OrderedDict()\n",
    "\n",
    "    neighbouring_pairs_list, prop_dicts = gen_neighbouring_pairs_list(df, interaction, aa_dict, cont_prop)\n",
    "    prop_dict = prop_dicts[cont_prop]\n",
    "    propensity_df, frequency_df, normed_frequencies_df = calc_aa_pair_propensities(neighbouring_pairs_list, aa_dict)\n",
    "    propensity_df = propensity_df.set_index('FASTA', drop=True)\n",
    "\n",
    "    for aa_1 in list(aa_dict.keys()):\n",
    "        for aa_2 in list(aa_dict.keys()):\n",
    "            all_aa_list = []\n",
    "            aa_1_list = []\n",
    "            aa_2_list = []\n",
    "            aa_1_aa_2_list = []\n",
    "\n",
    "            for aa_pair in list(prop_dict.keys()):\n",
    "                aas = aa_pair.split('_')[2:]\n",
    "\n",
    "                all_aa_list.append(prop_dict[aa_pair][0])\n",
    "                if aa_1 == aas[0]:\n",
    "                    aa_1_list.append(prop_dict[aa_pair][0])\n",
    "                if aa_2 == aas[-1]:\n",
    "                    aa_2_list.append(prop_dict[aa_pair][0])  # Want z_coords of aas interacting with aa_2\n",
    "                if aa_1 == aas[0] and aa_2 == aas[-1]:\n",
    "                    aa_1_aa_2_list.append(prop_dict[aa_pair][0])\n",
    "\n",
    "            if (\n",
    "                    (not np.isnan(propensity_df[aa_1][aa_2]))\n",
    "                and (min([len(all_aa_list), len(aa_1_list), len(aa_2_list), len(aa_1_aa_2_list)]) >= 10)\n",
    "            ):\n",
    "                print('Propensity for {} to interact with {}'.format(aa_1, aa_2))\n",
    "\n",
    "                plt.clf()\n",
    "                all_aa_array = np.asarray(all_aa_list)\n",
    "                all_aa_array = all_aa_array.astype(np.float64)\n",
    "                x_all_aa_list, y_all_aa_list = sns.distributions._statsmodels_univariate_kde(\n",
    "                    data=all_aa_array, kernel='gau', bw='scott', gridsize=100, cut=3, clip=(-np.inf, np.inf),\n",
    "                    cumulative=False\n",
    "                )\n",
    "\n",
    "                plt.clf()\n",
    "                aa_1_array = np.asarray(aa_1_list)\n",
    "                aa_1_array = aa_1_array.astype(np.float64)\n",
    "                x_aa_1_list, y_aa_1_list = sns.distributions._statsmodels_univariate_kde(\n",
    "                    data=aa_1_array, kernel='gau', bw='scott', gridsize=100, cut=3, clip=(-np.inf, np.inf),\n",
    "                    cumulative=False\n",
    "                )\n",
    "\n",
    "                plt.clf()\n",
    "                aa_2_array = np.asarray(aa_2_list)\n",
    "                aa_2_array = aa_2_array.astype(np.float64)\n",
    "                x_aa_2_list, y_aa_2_list = sns.distributions._statsmodels_univariate_kde(\n",
    "                    data=aa_2_array, kernel='gau', bw='scott', gridsize=100, cut=3, clip=(-np.inf, np.inf),\n",
    "                    cumulative=False\n",
    "                )\n",
    "\n",
    "                plt.clf()\n",
    "                aa_1_aa_2_array = np.asarray(aa_1_aa_2_list)\n",
    "                aa_1_aa_2_array = aa_1_aa_2_array.astype(np.float64)\n",
    "                x_aa_1_aa_2_list, y_aa_1_aa_2_list = sns.distributions._statsmodels_univariate_kde(\n",
    "                    data=aa_1_aa_2_array, kernel='gau', bw='scott', gridsize=100, cut=3, clip=(-np.inf, np.inf),\n",
    "                    cumulative=False\n",
    "                )\n",
    "\n",
    "                x_coord_lists = [x_all_aa_list, x_aa_1_list, x_aa_2_list]\n",
    "                y_coord_lists = [y_all_aa_list, y_aa_1_list, y_aa_2_list]\n",
    "\n",
    "                x_aa_1_aa_2_list_copy = list(copy.deepcopy(x_aa_1_aa_2_list))\n",
    "                interpolated_y_coord_lists = [(['']*len(x_aa_1_aa_2_list_copy)) for num in range(3)]\n",
    "                propensities = ['']*len(x_aa_1_aa_2_list_copy)\n",
    "\n",
    "                x_min = max([min(all_aa_list), min(aa_1_list), min(aa_2_list), min(aa_1_aa_2_list)])\n",
    "                x_max = min([max(all_aa_list), max(aa_1_list), max(aa_2_list), max(aa_1_aa_2_list)])\n",
    "\n",
    "                for index_1, value_1 in np.ndenumerate(x_aa_1_aa_2_list):\n",
    "                    index_1 = index_1[0]\n",
    "                    x_aa_1_aa_2 = x_aa_1_aa_2_list[index_1]\n",
    "                    y_aa_1_aa_2 = y_aa_1_aa_2_list[index_1]\n",
    "\n",
    "                    if (\n",
    "                           x_aa_1_aa_2 < x_min\n",
    "                        or x_aa_1_aa_2 > x_max\n",
    "                    ):\n",
    "                        x_aa_1_aa_2_list_copy[index_1] = ''\n",
    "                    else:\n",
    "                        for index_2, value_2 in np.ndenumerate(x_coord_lists):\n",
    "                            index_2 = index_2[0]\n",
    "                            x_coord_list = x_coord_lists[index_2]\n",
    "                            y_coord_list = y_coord_lists[index_2]\n",
    "\n",
    "                            interpolate_x_indices = []\n",
    "                            for index_3, value_3 in np.ndenumerate(x_coord_list):\n",
    "                                index_3 = index_3[0]\n",
    "                                x_coord = copy.deepcopy(value_3)\n",
    "                                if x_aa_1_aa_2 == x_coord:\n",
    "                                    if index_3 != (len(x_coord_list)-1):\n",
    "                                        interpolate_x_indices = [index_3, index_3+1]\n",
    "                                    else:\n",
    "                                        interpolate_x_indices = [index_3-1, index_3]\n",
    "                                    break\n",
    "                                elif x_coord_list[index_3] < x_aa_1_aa_2 and x_coord_list[index_3+1] > x_aa_1_aa_2:\n",
    "                                    interpolate_x_indices = [index_3, index_3+1]\n",
    "                                    break\n",
    "\n",
    "                            # Linear interpolation\n",
    "                            x_1 = x_coord_list[interpolate_x_indices[0]]\n",
    "                            x_2 = x_coord_list[interpolate_x_indices[1]]\n",
    "                            y_1 = y_coord_list[interpolate_x_indices[0]]\n",
    "                            y_2 = y_coord_list[interpolate_x_indices[1]]\n",
    "\n",
    "                            y_1_weight = abs(x_2 - x_aa_1_aa_2) / abs(x_2 - x_1)\n",
    "                            y_2_weight = abs(x_aa_1_aa_2 - x_1) / abs(x_2 - x_1)\n",
    "\n",
    "                            y = (y_1*y_1_weight) + (y_2*y_2_weight)\n",
    "                            interpolated_y_coord_lists[index_2][index_1] = y\n",
    "\n",
    "\n",
    "                for index_1, value_1 in enumerate(x_aa_1_aa_2_list_copy):\n",
    "                    if value_1 != '':\n",
    "                        y_all_aa = interpolated_y_coord_lists[0][index_1]\n",
    "                        y_aa_1 = interpolated_y_coord_lists[1][index_1]\n",
    "                        y_aa_2 = interpolated_y_coord_lists[2][index_1]\n",
    "                        y_aa_1_aa_2 = y_aa_1_aa_2_list[index_1]\n",
    "                        y_ratio = ((y_aa_1_aa_2 / y_aa_1)\n",
    "                                   / (y_aa_2 / y_all_aa))\n",
    "\n",
    "                        propensity = y_ratio * propensity_df[aa_1][aa_2]\n",
    "                        propensities[index_1] = propensity\n",
    "\n",
    "                # Plots kernel density estimates used in the calculation of the pairwise amino acid propensity plot\n",
    "                plt.clf()\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                ax = plt.gca()\n",
    "                sns.distplot(all_aa_list, hist=False, rug=True, kde_kws={'bw':'scott'}, rug_kws={'alpha': 0.1})\n",
    "                sns.distplot(aa_1_list, hist=False, rug=True, kde_kws={'bw':'scott'}, rug_kws={'alpha': 0.4})\n",
    "                sns.distplot(aa_2_list, hist=False, rug=True, kde_kws={'bw':'scott'}, rug_kws={'alpha': 0.4})\n",
    "                sns.distplot(aa_1_aa_2_list, hist=False, rug=True, kde_kws={'bw':'scott'}, rug_kws={'alpha': 0.8})\n",
    "                plt.show()\n",
    "\n",
    "                # Plots pairwise amino acid propensities vs. z-coordinate\n",
    "                x_aa_1_aa_2_list_copy = [x for x in x_aa_1_aa_2_list_copy if x != '']\n",
    "                propensities = [y for y in propensities if y != '']\n",
    "\n",
    "                plt.clf()\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                ax = plt.gca()\n",
    "                plt.plot(np.array(x_aa_1_aa_2_list_copy), np.array(propensities))\n",
    "                plt.show()\n",
    "\n",
    "                # Updates dictionary of amino acid propensities\n",
    "                propensities_dict['{}_{}'.format(aa_1, aa_2)] = np.array([x_aa_1_aa_2_list_copy,\n",
    "                                                                          propensities])\n",
    "                \n",
    "    return propensities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_pairwise_aa_propensities(df, interaction, prop_1, prop_2, aa_dict, cont_prop_1_range, cont_prop_2_range):\n",
    "    \"\"\"\n",
    "    Calculates propensities of the different amino acids to interact with one another vs. two continuous properties\n",
    "    of interest (e.g. phi and psi).\n",
    "    Input: dataframe of barrel / sandwich properties, name of continuous property 1 (specified by the name of its\n",
    "           corresponding column in the input dataframe), name of continuous property 2 (specified by the name of\n",
    "           its corresponding column in the input dataframe), dictionary of amino acid abbreviations, range of values\n",
    "           over which to calculate propensity values for continuous property 1, and range of values over which to\n",
    "           calculate propensity values for continuous property 2\n",
    "    \"\"\"\n",
    "    for prop in [prop_1, prop_2]:\n",
    "        df = df[~df[prop].isin(['', 'NaN', 'nan', np.nan])]\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    propensities_dict = OrderedDict()\n",
    "\n",
    "    neighbouring_pairs_list, prop_dicts = gen_neighbouring_pairs_list(\n",
    "        df, interaction, aa_dict, prop_1, prop_2\n",
    "    )\n",
    "    prop_1_dict = prop_dicts[prop_1]\n",
    "    prop_2_dict = prop_dicts[prop_2]\n",
    "    propensity_df, frequency_df, normed_frequencies_df = calc_aa_pair_propensities(neighbouring_pairs_list, aa_dict)\n",
    "    propensity_df = propensity_df.set_index('FASTA', drop=True)\n",
    "\n",
    "    for aa_1 in list(aa_dict.keys()):\n",
    "        for aa_2 in list(aa_dict.keys()):\n",
    "            all_aa_prop_1_list = []\n",
    "            aa_1_prop_1_list = []\n",
    "            aa_2_prop_1_list = []\n",
    "            aa_1_aa_2_prop_1_list = []\n",
    "            all_aa_prop_2_list = []\n",
    "            aa_1_prop_2_list = []\n",
    "            aa_2_prop_2_list = []\n",
    "            aa_1_aa_2_prop_2_list = []\n",
    "\n",
    "            for aa_pair in list(prop_1_dict.keys()):\n",
    "                aas = aa_pair.split('_')[2:]\n",
    "\n",
    "                all_aa_prop_1_list.append(prop_1_dict[aa_pair][0])\n",
    "                all_aa_prop_2_list.append(prop_2_dict[aa_pair][0])\n",
    "                if aa_1 == aas[0]:\n",
    "                    aa_1_prop_1_list.append(prop_1_dict[aa_pair][0])\n",
    "                    aa_1_prop_2_list.append(prop_2_dict[aa_pair][0])\n",
    "                if aa_2 == aas[-1]:\n",
    "                    aa_2_prop_1_list.append(prop_1_dict[aa_pair][0])  # Want z_coords of aas interacting with aa_2\n",
    "                    aa_2_prop_2_list.append(prop_2_dict[aa_pair][0])  # Want z_coords of aas interacting with aa_2\n",
    "                if aa_1 == aas[0] and aa_2 == aas[-1]:\n",
    "                    aa_1_aa_2_prop_1_list.append(prop_1_dict[aa_pair][0])\n",
    "                    aa_1_aa_2_prop_2_list.append(prop_2_dict[aa_pair][0])\n",
    "\n",
    "            if (\n",
    "                    (not np.isnan(propensity_df[aa_1][aa_2]))\n",
    "                and (min([len(all_aa_prop_1_list), len(aa_1_prop_1_list),\n",
    "                          len(aa_2_prop_1_list), len(aa_1_aa_2_prop_1_list),\n",
    "                          len(all_aa_prop_2_list), len(aa_1_prop_2_list),\n",
    "                          len(aa_2_prop_2_list), len(aa_1_aa_2_prop_2_list)]) >= 10)\n",
    "            ):\n",
    "                print('Propensity for {} to interact with {}'.format(aa_1, aa_2))\n",
    "\n",
    "                plt.clf()\n",
    "                all_aa_prop_1 = np.asarray(all_aa_prop_1_list)\n",
    "                all_aa_prop_1 = all_aa_prop_1.astype(np.float64)\n",
    "                all_aa_prop_2 = np.asarray(all_aa_prop_2_list)\n",
    "                all_aa_prop_2 = all_aa_prop_2.astype(np.float64)\n",
    "                x_all_aa_list, y_all_aa_list, z_all_aa_list = sns.distributions._statsmodels_bivariate_kde(\n",
    "                    x=all_aa_prop_1, y=all_aa_prop_2, bw='scott', gridsize=100, cut=3,\n",
    "                    clip=[(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "                )\n",
    "\n",
    "                plt.clf()\n",
    "                aa_1_prop_1 = np.asarray(aa_1_prop_1_list)\n",
    "                aa_1_prop_1 = aa_1_prop_1.astype(np.float64)\n",
    "                aa_1_prop_2 = np.asarray(aa_1_prop_2_list)\n",
    "                aa_1_prop_2 = aa_1_prop_2.astype(np.float64)\n",
    "                x_aa_1_list, y_aa_1_list, z_aa_1_list = sns.distributions._statsmodels_bivariate_kde(\n",
    "                    x=aa_1_prop_1, y=aa_1_prop_2, bw='scott', gridsize=100, cut=3,\n",
    "                    clip=[(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "                )\n",
    "\n",
    "                plt.clf()\n",
    "                aa_2_prop_1 = np.asarray(aa_2_prop_1_list)\n",
    "                aa_2_prop_1 = aa_2_prop_1.astype(np.float64)\n",
    "                aa_2_prop_2 = np.asarray(aa_2_prop_2_list)\n",
    "                aa_2_prop_2 = aa_2_prop_2.astype(np.float64)\n",
    "                x_aa_2_list, y_aa_2_list, z_aa_2_list = sns.distributions._statsmodels_bivariate_kde(\n",
    "                    x=aa_2_prop_1, y=aa_2_prop_2, bw='scott', gridsize=100, cut=3,\n",
    "                    clip=[(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "                )\n",
    "\n",
    "                plt.clf()\n",
    "                aa_1_aa_2_prop_1 = np.asarray(aa_1_aa_2_prop_1_list)\n",
    "                aa_1_aa_2_prop_1 = aa_1_aa_2_prop_1.astype(np.float64)\n",
    "                aa_1_aa_2_prop_2 = np.asarray(aa_1_aa_2_prop_2_list)\n",
    "                aa_1_aa_2_prop_2 = aa_1_aa_2_prop_2.astype(np.float64)\n",
    "                x_aa_1_aa_2_list, y_aa_1_aa_2_list, z_aa_1_aa_2_list = sns.distributions._statsmodels_bivariate_kde(\n",
    "                    x=aa_1_aa_2_prop_1, y=aa_1_aa_2_prop_2, bw='scott', gridsize=100, cut=3,\n",
    "                    clip=[(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "                )\n",
    "\n",
    "                x_coord_lists = [x_all_aa_list, x_aa_1_list, x_aa_2_list]\n",
    "                y_coord_lists = [y_all_aa_list, y_aa_1_list, y_aa_2_list]\n",
    "                z_coord_lists = [z_all_aa_list, z_aa_1_list, z_aa_2_list]\n",
    "\n",
    "                propensities = np.full(z_aa_1_aa_2_list.shape, np.nan)\n",
    "\n",
    "                for index_1, value_1 in np.ndenumerate(z_aa_1_aa_2_list):\n",
    "                    column = index_1[0]\n",
    "                    row = index_1[1]\n",
    "\n",
    "                    x_aa_1_aa_2 = x_aa_1_aa_2_list[column][row]\n",
    "                    y_aa_1_aa_2 = y_aa_1_aa_2_list[column][row]\n",
    "                    z_aa_1_aa_2 = z_aa_1_aa_2_list[column][row]\n",
    "\n",
    "                    # Finds x,y pairs in overall z distribution for interpolation\n",
    "                    if (\n",
    "                            x_aa_1_aa_2 >= cont_prop_1_range[0]\n",
    "                        and x_aa_1_aa_2 <= cont_prop_1_range[1]\n",
    "                        and y_aa_1_aa_2 >= cont_prop_2_range[0]\n",
    "                        and y_aa_1_aa_2 <= cont_prop_2_range[1]\n",
    "                    ):\n",
    "                        interpolated_z_vals = []\n",
    "\n",
    "                        for index_2, value_2 in enumerate(x_coord_lists):\n",
    "                            x_coord_list = x_coord_lists[index_2][0]\n",
    "                            y_coord_list = np.transpose(y_coord_lists[index_2])[0]\n",
    "                            z_coord_list = z_coord_lists[index_2]\n",
    "\n",
    "                            interpolate_x_indices = []\n",
    "                            for index_3, value_3 in np.ndenumerate(x_coord_list):\n",
    "                                index_3 = index_3[0]\n",
    "                                x_coord = copy.deepcopy(value_3)\n",
    "                                if x_aa_1_aa_2 == x_coord:\n",
    "                                    if index_3 < (len(x_coord_list)-1):\n",
    "                                        interpolate_x_indices = [index_3, index_3+1]\n",
    "                                    else:\n",
    "                                        interpolate_x_indices = [index_3-1, index_3]\n",
    "                                    break\n",
    "                                elif (\n",
    "                                          x_coord_list[index_3] < x_aa_1_aa_2\n",
    "                                      and x_coord_list[index_3+1] > x_aa_1_aa_2\n",
    "                                ):\n",
    "                                    interpolate_x_indices = [index_3, index_3+1]\n",
    "                                    break\n",
    "\n",
    "                            interpolate_y_indices = []\n",
    "                            for index_4, value_4 in np.ndenumerate(y_coord_list):\n",
    "                                index_4 = index_4[0]\n",
    "                                y_coord = copy.deepcopy(value_4)\n",
    "                                if y_aa_1_aa_2 == y_coord:\n",
    "                                    if index_4 < (len(y_coord_list)-1):\n",
    "                                        interpolate_y_indices = [index_4, index_4+1]\n",
    "                                    else:\n",
    "                                        interpolate_y_indices = [index_4-1, index_4]\n",
    "                                    break\n",
    "                                elif (\n",
    "                                          y_coord_list[index_4] < y_aa_1_aa_2\n",
    "                                      and y_coord_list[index_4+1] > y_aa_1_aa_2\n",
    "                                ):\n",
    "                                    interpolate_y_indices = [index_4, index_4+1]\n",
    "                                    break\n",
    "\n",
    "                            # Bilinear interpolation\n",
    "                            x1 = x_coord_list[interpolate_x_indices[0]]\n",
    "                            x2 = x_coord_list[interpolate_x_indices[1]]\n",
    "                            y1 = y_coord_list[interpolate_y_indices[0]]\n",
    "                            y2 = y_coord_list[interpolate_y_indices[1]]\n",
    "                            z_x1y1 = z_coord_list[interpolate_y_indices[0]][interpolate_x_indices[0]]\n",
    "                            z_x2y1 = z_coord_list[interpolate_y_indices[0]][interpolate_x_indices[1]]\n",
    "                            z_x1y2 = z_coord_list[interpolate_y_indices[1]][interpolate_x_indices[0]]\n",
    "                            z_x2y2 = z_coord_list[interpolate_y_indices[1]][interpolate_x_indices[1]]\n",
    "\n",
    "                            x1_weight = abs(x2 - x_aa_1_aa_2) / abs(x2 - x1)\n",
    "                            x2_weight = abs(x_aa_1_aa_2 - x1) / abs(x2 - x1)\n",
    "                            y1_weight = abs(y2 - y_aa_1_aa_2) / abs(y2 - y1)\n",
    "                            y2_weight = abs(y_aa_1_aa_2 - y1) / abs(y2 - y1)\n",
    "\n",
    "                            z_xy1 = (z_x1y1*x1_weight) + (z_x2y1*x2_weight)\n",
    "                            z_xy2 = (z_x1y2*x1_weight) + (z_x2y2*x2_weight)\n",
    "\n",
    "                            z = (z_xy1*y1_weight)+(z_xy2*y2_weight)\n",
    "                            interpolated_z_vals.append(z)\n",
    "\n",
    "                        z_all_aa = interpolated_z_vals[0]\n",
    "                        z_aa_1 = interpolated_z_vals[1]\n",
    "                        z_aa_2 = interpolated_z_vals[2]\n",
    "                        z_ratio = ((z_aa_1_aa_2 / z_aa_1)\n",
    "                                   / (z_aa_2 / z_all_aa))\n",
    "                        propensity = z_ratio * propensity_df[aa_1][aa_2]\n",
    "                        propensities[column][row] = propensity\n",
    "\n",
    "                # Plots individual pairwise KDEs used in propensity calculation\n",
    "                plt.clf()\n",
    "                fig, ax = plt.subplots(figsize=(15, 5))\n",
    "                contours_1 = ax.contour(x_all_aa_list, y_all_aa_list, z_all_aa_list, 10, cmap='Blues')\n",
    "                colourbar_1 = fig.colorbar(contours_1)\n",
    "                contours_2 = ax.contour(x_aa_1_list, y_aa_1_list, z_aa_1_list, 10, cmap='Oranges')\n",
    "                colourbar_2 = fig.colorbar(contours_2)\n",
    "                contours_3 = ax.contour(x_aa_2_list, y_aa_2_list, z_aa_2_list, 10, cmap='Greens')\n",
    "                colourbar_3 = fig.colorbar(contours_3)\n",
    "                contours_4 = ax.contour(x_aa_1_aa_2_list, y_aa_1_aa_2_list, z_aa_1_aa_2_list, 10, cmap='RdPu')\n",
    "                colourbar_4 = fig.colorbar(contours_4)\n",
    "                plt.show()\n",
    "\n",
    "                # Plots propensity KDE\n",
    "                plt.clf()\n",
    "                fig, ax = plt.subplots(figsize=(8, 5))\n",
    "                contours_1 = ax.contour(x_aa_1_aa_2_list, y_aa_1_aa_2_list, propensities, 10, cmap='RdPu')\n",
    "                colourbar_1 = fig.colorbar(contours_1)\n",
    "                plt.show()\n",
    "                \n",
    "                # Updates dictionary of amino acid propensities\n",
    "                propensities_dict['{}_{}'.format(aa_1, aa_2)] = np.array([x_aa_1_aa_2_list,\n",
    "                                                                          y_aa_1_aa_2_list,\n",
    "                                                                          propensities])\n",
    "                \n",
    "    return propensities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discrete_prop_frequency_kdes(df, cont_prop, discrete_props):\n",
    "    \"\"\"\n",
    "    Plots kernel density estimate of the distribution of a discrete property (e.g. the number of interactions of a\n",
    "    particular type (e.g. hydrogen bonds) formed by an amino acid)  vs. a continuous property (typically z-coordinate)\n",
    "    Input: dataframe of barrel / sandwich properties, name of continuous property of interest (specified via the\n",
    "           name of the corresponding column in the input dataframe), and list of discrete properties (each discrete\n",
    "           property is considered individually, in a separate kde plot)\n",
    "    \"\"\"\n",
    "    domain_res_ids_list = []\n",
    "    for row in range(df.shape[0]):\n",
    "        domain_res_id = df['domain_ids'][row] + df['res_ids'][row]\n",
    "        domain_res_ids_list.append(domain_res_id)\n",
    "\n",
    "    for discrete_prop in discrete_props:\n",
    "        print(discrete_prop)\n",
    "\n",
    "        cont_prop_distribution = []\n",
    "        for row in range(df.shape[0]):\n",
    "            interacting_domain_neighbours = []\n",
    "\n",
    "            for res_id in df[discrete_prop][row]:\n",
    "                domain_res_id = df['domain_ids'][row] + res_id\n",
    "                # Only considers interactions with residues that are also within the domain\n",
    "                if domain_res_id in domain_res_ids_list:\n",
    "                    interacting_domain_neighbours.append(domain_res_id)\n",
    "\n",
    "            interaction_num = len(interacting_domain_neighbours)\n",
    "            count = 0\n",
    "            while count < interaction_num:\n",
    "                cont_prop_distribution.append(df[cont_prop][row])\n",
    "                count += 1\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.distplot(pd.DataFrame({cont_prop: cont_prop_distribution}), hist=False, rug=True,\n",
    "                     kde_kws={'bw':'scott'}, rug_kws={'alpha': 0.1})\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prop_vs_prop(df, cont_prop_1, cont_prop_dict_2, cont_prop_2, bw_1, bw_2):\n",
    "    \"\"\"\n",
    "    Plots the 2D kernel desity estimate of two continuous properties\n",
    "    Input: dataframe of barrel / sandwich properties, name of first continuous property of interest (specified via\n",
    "           the name of the corresponding column in the input dataframe), dictionary of amino acid identities vs.\n",
    "           their values of the second continuous property of interest, the name of the second continuous property\n",
    "           of interest, the kernel bandwidth of the first property and the kernel bandwidth of the second property\n",
    "    \"\"\"\n",
    "    cont_prop_2_list = ['']*df.shape[0]\n",
    "    unprocessed_indices = []\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        fasta = df['fasta_seq'][row]\n",
    "\n",
    "        if fasta in cont_prop_dict_2:\n",
    "            cont_prop_2_list[row] = cont_prop_dict_2[fasta]\n",
    "        else:\n",
    "            unprocessed_indices.append(row)\n",
    "\n",
    "    cont_prop_1_list = [val for index, val in enumerate(df[cont_prop_1].tolist()) if not index in unprocessed_indices]\n",
    "    cont_prop_2_list = [val for index, val in enumerate(cont_prop_2_list) if not index in unprocessed_indices]\n",
    "\n",
    "    prop_df = pd.DataFrame({cont_prop_1: cont_prop_1_list,\n",
    "                            cont_prop_2: cont_prop_2_list})\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.kdeplot(data=prop_df[cont_prop_1], data2=prop_df[cont_prop_2], bw=(bw_1,bw_2), shade=True, cbar=True)\n",
    "    # plt.scatter(prop_df[cont_prop_1], prop_df[cont_prop_2], marker='.', c='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prop_vs_dihedral(df, cont_prop, dihedral):\n",
    "    \"\"\"\n",
    "    Plots the 2D kernel desity estimate of a continuous property of interest vs. a dihedral angle\n",
    "    Input: dataframe of barrel / sandwich properties, name of continuous property of interest (specified via\n",
    "           the name of the corresponding column in the input dataframe), name of dihedral angle of interest\n",
    "           (specified via the name of the corresponding column in the input dataframe)\n",
    "    \"\"\"\n",
    "    df = df[~df[dihedral].isin(['', 'NaN', 'nan', np.nan])]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    dihedral_df = pd.DataFrame({cont_prop: df[cont_prop].tolist(),\n",
    "                                dihedral: df[dihedral].tolist()})\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.kdeplot(data=dihedral_df[cont_prop], data2=dihedral_df[dihedral], bw='scott', shade=True, cbar=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(df, cont_prop):\n",
    "    \"\"\"\n",
    "    Generates ordered array of a (numeric) property of interest in the input dataframe, without '', 'NaN', 'nan'\n",
    "    and np.nan values\n",
    "    Input: dataframe of barrel / sandwich properties, name of property of interest (specified via the name of\n",
    "           the corresponding column in the input dataframe)\n",
    "    Returns: ordered numpy array of the property of interest\n",
    "    \"\"\"\n",
    "    cont_prop_vals = df[cont_prop].tolist()\n",
    "    cont_prop_vals = remove_nan(cont_prop_vals)\n",
    "    cont_prop_vals = np.array(sorted(cont_prop_vals))\n",
    "\n",
    "    return cont_prop_vals\n",
    "\n",
    "\n",
    "def gen_random_array(ordered_array):\n",
    "    \"\"\"\n",
    "    Generates a random array by sampling, with replacement, an input array\n",
    "    Input: ordered array\n",
    "    Returns: ordered array (of the same length as the input array) generated by sampling the input array with\n",
    "             replacement\n",
    "    \"\"\"\n",
    "    random_array = np.empty(len(ordered_array),)\n",
    "\n",
    "    for num in range(len(ordered_array)):\n",
    "        rand_index = random.randint(0, (len(ordered_array)-1))\n",
    "        rand_z_coord = ordered_array[rand_index]\n",
    "        random_array[num] = rand_z_coord\n",
    "\n",
    "    return np.sort(random_array)\n",
    "\n",
    "\n",
    "def run_ks_2samp_test(df, cont_prop, aa, bootstrap):\n",
    "    \"\"\"\n",
    "    Runs the 1D 2 sample Kolmogorov-Smirnov test with scipy to calculate the likelihood that two samples come from\n",
    "    the same distribution (where sample 1 is the distribution of an individual amino acid with respect to a\n",
    "    continuous property of interest (typically z-coordinate), and sample 2 is the distribution of all amino acids\n",
    "    with respect to that property)\n",
    "    Input: dataframe of barrel / sandwich properties, name of the continuous property of interest (specified via\n",
    "           the name of the corresponding column in the input dataframe), the name of the individual amino acid, and\n",
    "           whether this test is being run as part of a bootstrap test or not\n",
    "    \"\"\"\n",
    "    df = df[~df[cont_prop].isin(['', 'NaN', 'nan', np.nan])]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    aa_df = df[df['fasta_seq'] == aa]\n",
    "    aa_df = aa_df.reset_index(drop=True)\n",
    "\n",
    "    indv_aa_cont_prop_vals = remove_nan(aa_df[cont_prop].tolist())\n",
    "    indv_aa_cont_prop_vals = np.array(sorted(indv_aa_cont_prop_vals))\n",
    "\n",
    "    # If performing bootstrap analysis, generate a random array from the df[cont_prop] distribution\n",
    "    if bootstrap:\n",
    "        indv_aa_cont_prop_vals = gen_random_array(indv_aa_cont_prop_vals)\n",
    "\n",
    "    D, p = scipy.stats.ks_2samp(indv_aa_cont_prop_vals, calc_dist(df, cont_prop))\n",
    "\n",
    "    return D, p\n",
    "\n",
    "\n",
    "def initial_ks_test(df, cont_prop, ks_func, aa_dict):\n",
    "    \"\"\"\n",
    "    Wrapper to run the 1D 2 sample Kolmogorov-Smirnov test for the original (i.e. not resampled) individual amino\n",
    "    acid distribution and the overall amino acid distribution\n",
    "    Input: dataframe of barrel / sandwich properties, name of the continuous property of interest (specified via\n",
    "           the name of the corresponding column in the input dataframe), the function to run the KS test, and\n",
    "           dictionary of amino acid abbreviations\n",
    "    Returns: dictionaries of D and p values output from KS test\n",
    "    \"\"\"\n",
    "    D_dict = OrderedDict()\n",
    "    p_dict = OrderedDict()\n",
    "\n",
    "    for aa in list(aa_dict.keys()):\n",
    "        D, p = ks_func(df, cont_prop, aa, False)\n",
    "        D_dict[aa] = [D]\n",
    "        p_dict[aa] = [p]\n",
    "\n",
    "    return D_dict, p_dict\n",
    "\n",
    "def bootstrap_ks_test(df, cont_prop, bootstrap_num, ks_func, aa_dict):\n",
    "    \"\"\"\n",
    "    Wrapper to run the 1D 2 sample Kolmogorov-Smirnov test a specified number of times on different resamplings\n",
    "    of the original individual amino acid distribution and the overall amino acid distribution\n",
    "    Input: dataframe of barrel / sandwich properties, name of the continuous property of interest (specified via\n",
    "           the name of the corresponding column in the input dataframe), the number of KS tests to run (i.e. the\n",
    "           size of the bootstrap), the function to run the KS test, dictionary of amino acid abbreviations\n",
    "    Returns: dictionaries of D and p values output from KS test\n",
    "    \"\"\"\n",
    "    D_dict = OrderedDict()\n",
    "    p_dict = OrderedDict()\n",
    "\n",
    "    for aa in list(aa_dict.keys()):\n",
    "        D_dict[aa] = []\n",
    "        p_dict[aa] = []\n",
    "\n",
    "    for num in range(bootstrap_num):\n",
    "        for aa in list(aa_dict.keys()):\n",
    "            D, p = ks_func(df, cont_prop, aa, True)\n",
    "            D_dict[aa].append(D)\n",
    "            p_dict[aa].append(p)\n",
    "\n",
    "    return D_dict, p_dict\n",
    "\n",
    "\n",
    "def draw_plot(plot_type, stat_dict, x_label, y_label):\n",
    "    \"\"\"\n",
    "    Generates swarmplot / violinplot of D / p values vs. amino acid identity\n",
    "    Input: name of plot ('sns.swarmplot' or 'sns.violinplot'), dictionary of D or p values, label for x-axis \n",
    "           (e.g. 'FASTA'), label for y-axis (e.g. 'D' or 'p')\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "\n",
    "    for key in list(stat_dict.keys()):\n",
    "        for value in stat_dict[key]:\n",
    "            x_values.append(key)\n",
    "            y_values.append(value)\n",
    "\n",
    "    # \"Melted\" df of aa vs. stat (either p or D)\n",
    "    df = pd.DataFrame({'{}'.format(x_label): x_values,\n",
    "                       '{}'.format(y_label): y_values})\n",
    "\n",
    "    plot_type(x='{}'.format(x_label), y='{}'.format(y_label), data=df)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calc_95_conf_limits(initial_stat_dict, bootstrap_stat_dict):\n",
    "    \"\"\"\n",
    "    Calculates 95% confidence limits on D / p from a bootstrap sample\n",
    "    Input: dictionary of D / p values for original individual amino acid samples, dictionary of D / p values for\n",
    "           bootstrapped individual amino acid samples\n",
    "    Returns: dictionary of 95% confidence intervals for D / p\n",
    "    \"\"\"\n",
    "    conf_int_dict = OrderedDict()\n",
    "\n",
    "    for aa in list(initial_stat_dict.keys()):\n",
    "        initial_stat = initial_stat_dict[aa][0]\n",
    "        bootstrap_stat_values = np.sort(np.array(bootstrap_stat_dict[aa]))\n",
    "\n",
    "        # Crude method of calculating 95% confidence interval, but good enough for my purposes (to complement\n",
    "        # \"by eye\" analysis)\n",
    "        lower_percentile = np.percentile(bootstrap_stat_values, 2.5)\n",
    "        upper_percentile = np.percentile(bootstrap_stat_values, 97.5)\n",
    "\n",
    "        conf_int_dict[aa] = [lower_percentile, initial_stat, upper_percentile]\n",
    "        \n",
    "    return conf_int_dict\n",
    "\n",
    "\n",
    "def iterate_bootstrap_conf_limits(df, cont_prop, ks_func, bootstrap_range, aa_dict):\n",
    "    \"\"\"\n",
    "    Performs KS test with increasing number of bootstrap samples and plots output to allow user to determine when the\n",
    "    confidence intervals converge (and so the minimum number of bootstrap samples they need to run)\n",
    "    Input: dataframe of barrel / sandwich properties, name of the continuous property of interest (typically\n",
    "           z-coordinate) (specified via the name of the corresponding column in the input dataframe), the function\n",
    "           to run the KS test, list of numbers of bootstrap samples to test (e.g. [100, 300, 1000, 3000, 10000, 30000,\n",
    "           100000]), dictionary of amino acid abbreviations\n",
    "    \"\"\"\n",
    "    initial_D_dict, initial_p_dict = initial_ks_test(df, cont_prop, ks_func, aa_dict)\n",
    "\n",
    "    bootstrap_D_dict = OrderedDict()\n",
    "    bootstrap_p_dict = OrderedDict()\n",
    "\n",
    "    for num in bootstrap_range:\n",
    "        print(num)\n",
    "        D_dict, p_dict = bootstrap_ks_test(df, cont_prop, num, ks_func, aa_dict)\n",
    "        bootstrap_D_dict[num] = D_dict\n",
    "        bootstrap_p_dict[num] = p_dict\n",
    "\n",
    "    bootstrap_conf_intv_D_dict = OrderedDict()\n",
    "    bootstrap_conf_intv_p_dict = OrderedDict()\n",
    "    for num in bootstrap_range:\n",
    "        conf_int_D_dict = calc_95_conf_limits(initial_D_dict, bootstrap_D_dict[num])\n",
    "        bootstrap_conf_intv_D_dict[num] = conf_int_D_dict\n",
    "        conf_int_p_dict = calc_95_conf_limits(initial_p_dict, bootstrap_p_dict[num])\n",
    "        bootstrap_conf_intv_p_dict[num] = conf_int_p_dict\n",
    "\n",
    "    for aa in list(aa_dict.keys()):\n",
    "        aa_bootstrap_D_dict = OrderedDict()\n",
    "        aa_bootstrap_p_dict = OrderedDict()\n",
    "        \n",
    "        for num in bootstrap_range:\n",
    "            aa_bootstrap_D_dict[num] = bootstrap_conf_intv_D_dict[num][aa]\n",
    "            aa_bootstrap_p_dict[num] = bootstrap_conf_intv_p_dict[num][aa]\n",
    "        \n",
    "        print(aa)\n",
    "        draw_plot(sns.swarmplot, aa_bootstrap_p_dict, 'Num_bootstrap_samples', 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pair_proportions(df, pair_type, aa_dict):\n",
    "    \"\"\"\n",
    "    For every pairwise combination of amino acids listed in the input dictionary of amino acid abbreviations, aa1aa2,\n",
    "    calculates proportions of amino acid pairs at a location of interest (e.g. HB, or NHB, pairs) that are of that\n",
    "    identity. Note no pair inversion.\n",
    "    Input: dataframe of sandwich / barrel properties, name of amino acid pair type of interest (specified via the\n",
    "           name of its corresponding column in the input dataframe), and dictionary of amino acid abbreviations\n",
    "    Returns: dictionary of aa1aa2 pair count, total number of amino acid pairs of type of interest\n",
    "    \"\"\"\n",
    "    neighbouring_pairs_list = gen_neighbouring_pairs_list(df, pair_type, aa_dict)\n",
    "\n",
    "    pairs_count_dict = OrderedDict()\n",
    "    for aa_pair in itertools.combinations_with_replacement(list(aa_dict.keys()), 2):\n",
    "        aa_pair = '{}_{}'.format(aa_pair[0], aa_pair[1])\n",
    "        pairs_count_dict[aa_pair] = 0\n",
    "\n",
    "    for aa_pair in neighbouring_pairs_list:\n",
    "        aa_1 = aa_pair.split('_')[0]\n",
    "        aa_2 = aa_pair.split('_')[1]\n",
    "        aa_pair_fwd = copy.deepcopy(aa_pair)\n",
    "        aa_pair_rev = aa_pair_fwd[::-1]\n",
    "\n",
    "        if (    aa_1 != aa_2\n",
    "            and aa_pair_fwd in list(pairs_count_dict.keys())\n",
    "            and aa_pair_rev in list(pairs_count_dict.keys())\n",
    "        ):\n",
    "            sys.exit('Error with standard error of proporton calculation')\n",
    "\n",
    "        if aa_pair_fwd in list(pairs_count_dict.keys()):\n",
    "            pairs_count_dict[aa_pair_fwd] += 1\n",
    "        elif aa_pair_rev in list(pairs_count_dict.keys()):\n",
    "            pairs_count_dict[aa_pair_rev] += 1\n",
    "\n",
    "    pairs_total = len(neighbouring_pairs_list)\n",
    "    for aa_pair in list(pairs_count_dict.keys()):\n",
    "        pairs_count_dict[aa_pair] = pairs_count_dict[aa_pair] / pairs_total\n",
    "\n",
    "    return pairs_count_dict, pairs_total\n",
    "\n",
    "\n",
    "def gen_dek_sandwich_dicts(aa_dict, hb_or_nhb):\n",
    "    \"\"\"\n",
    "    Reads beta-sandwich HB / NHB count data from Dek's 1998 paper (which is stored in two separate csv files in\n",
    "    the BetaStats directory) into a dictionary\n",
    "    Input: dictionary of amino acid abbreviations, and whether to read in HB (hb_or_nhb = 'hb') or NHB\n",
    "           (hb_or_nhb = 'nhb') count data\n",
    "    Returns: dictionary of amino acid pair proportions, total number of HB (hb_or_nhb = 'hb') or NHB\n",
    "             (hb_or_nhb = 'nhb') amino acid pairs\n",
    "    \"\"\"\n",
    "    pairs_count_dict = OrderedDict()\n",
    "    for aa_pair in itertools.combinations_with_replacement(list(aa_dict.keys()), 2):\n",
    "        aa_pair = '{}_{}'.format(aa_pair[0], aa_pair[1])\n",
    "        pairs_count_dict[aa_pair] = 0\n",
    "        \n",
    "    file_name = 'Beta_{}_count_data_Hutchinson_et_al_1998.csv'.format(hb_or_nhb.upper())\n",
    "    df = pd.read_csv(file_name, header=0, index_col=0)\n",
    "    for col in df.columns.values.tolist():\n",
    "        df[col] = pd.to_numeric(df[col].tolist())\n",
    "\n",
    "    pairs_total = 0\n",
    "    for aa_pair in list(pairs_count_dict.keys()):\n",
    "        aa_1 = aa_pair.split('_')[0]\n",
    "        aa_2 = aa_pair.split('_')[1]\n",
    "\n",
    "        count = df[aa_1][aa_2]\n",
    "        pairs_total += count\n",
    "        pairs_count_dict[aa_pair] = count\n",
    "\n",
    "    for aa_pair in list(pairs_count_dict.keys()):\n",
    "        pairs_count_dict[aa_pair] = pairs_count_dict[aa_pair] / pairs_total\n",
    "\n",
    "    return pairs_count_dict, pairs_total\n",
    "\n",
    "\n",
    "def calc_std_error_proportion(aa_dict, hb_pairs_count_dict, nhb_pairs_count_dict, hb_pairs_total,\n",
    "                              nhb_pairs_total):\n",
    "    \"\"\"\n",
    "    Calculates standard error of proportion of amino acid pairs that form HB as compared with NHB pairs. These\n",
    "    results can be used to determine if there is a significant difference between the proportion of aa1aa2 pairs\n",
    "    at HB positions as compared to NHB positions.\n",
    "    Input: dictionary of amino acid abbreviations, dictionary of hydrogen bonding pair probabilities, dictionary\n",
    "           of non-hydrogen-bonding pair probabilities, total number of hydrogen bonding pairs, total number of\n",
    "           non-hydrogen-bonding pairs\n",
    "    dataframe of barrel / sandwich properties, dictionary of amino acid abbreviations\n",
    "    Returns: dictionary of z scores, dictionary of ratios of proportion of aa1aa2 pairs at HB sites to proportion\n",
    "             of aa1aa2 pairs at NHB sites\n",
    "    \"\"\"\n",
    "    z_score_dict = OrderedDict()\n",
    "    ratios_dict = OrderedDict()\n",
    "    for aa_pair in itertools.combinations_with_replacement(list(aa_dict.keys()), 2):\n",
    "        aa_pair = '{}_{}'.format(aa_pair[0], aa_pair[1])\n",
    "        z_score_dict[aa_pair] = np.nan\n",
    "        ratios_dict[aa_pair] = np.nan\n",
    "\n",
    "    for aa_pair in list(hb_pairs_count_dict):\n",
    "        p_hb = hb_pairs_count_dict[aa_pair]\n",
    "        p_nhb = nhb_pairs_count_dict[aa_pair]\n",
    "        \n",
    "        if p_hb > 0 and p_nhb > 0:\n",
    "            variance_hb = (p_hb*(1-p_hb)) / hb_pairs_total\n",
    "            variance_nhb = (p_nhb*(1-p_nhb)) / nhb_pairs_total\n",
    "\n",
    "            std_dev = (variance_hb + variance_nhb)**0.5\n",
    "            z = (p_hb - p_nhb) / std_dev\n",
    "            z_score_dict[aa_pair] = z\n",
    "            \n",
    "            ratios_dict[aa_pair] = p_hb / p_nhb\n",
    "\n",
    "    return z_score_dict, ratios_dict\n",
    "\n",
    "\n",
    "def print_significant_z_scores(z_score_dict):\n",
    "    \"\"\"\n",
    "    Prints z-scores above / below 95 and 99% confidence limits\n",
    "    Input: dictionary of z scores\n",
    "    \"\"\"\n",
    "    for aa_pair, score in z_score_dict.items():\n",
    "        if score > 2.58:\n",
    "            print('Outside 99% confidence limit, favours HB: {}'.format(aa_pair))\n",
    "        elif 1.96 < score <= 2.58:\n",
    "            print('Outside 95% confidence limit, favours HB: {}'.format(aa_pair))\n",
    "        elif score < -2.58:\n",
    "            print('Outside 99% confidence limit, favours NHB: {}'.format(aa_pair))\n",
    "        elif -2.58 <= score < -1.96:\n",
    "            print('Outside 95% confidence limit, favours NHB: {}'.format(aa_pair))\n",
    "\n",
    "\n",
    "def calc_z_diff(z_score_dict, dek_sandwich_z_dict):\n",
    "    \"\"\"\n",
    "    Calculates the difference in area underneath the normal distribution curve between two z-scores\n",
    "    Input: first dictionary of z scores, second dictionary of z scores\n",
    "    Returns: dictionary of differences\n",
    "    \"\"\"\n",
    "    z_diff_dict = OrderedDict()\n",
    "\n",
    "    for aa_pair in list(z_score_dict.keys()):\n",
    "        z_score_old = dek_sandwich_z_dict[aa_pair]\n",
    "        z_score_new = z_score_dict[aa_pair]\n",
    "        \n",
    "        p_old = scipy.stats.norm.cdf(z_score_old)\n",
    "        p_new = scipy.stats.norm.cdf(z_score_new)\n",
    "        \n",
    "        area_diff = abs(p_new - p_old)\n",
    "        z_diff_dict[aa_pair] = area_diff\n",
    "\n",
    "    return z_diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrel_file_loc = (\n",
    "    '/Users/ks17361/Lab_work_DW/Beta_structure/Parametrisation/My_beta_sandwich_and_barrel_datasets/'\n",
    "    'Beta_Datasets_30_10_2018/seqid_40/CATH_2.40.160_2.40.170_2.40.230_2.40.128_resn_2.5_rfac_0.3_ba/'\n",
    "    'Beta_res_dataframe.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrel_df = pd.read_pickle(barrel_file_loc)\n",
    "barrel_df = barrel_df[barrel_df['fasta_seq'].isin(list(aa_dict.keys()))]\n",
    "barrel_df = barrel_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amino acid distribution in beta-barrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrel_distribution = calc_distribution(barrel_df, aa_dict)\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='FASTA', y='Normalised frequency', data=barrel_distribution)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aa in list(aa_dict.keys()):\n",
    "    print(aa + ': ' + str(barrel_df['fasta_seq'].tolist().count(aa)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too few Cys residues for meaningful analysis => discounted from further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict_no_cys = copy.deepcopy(aa_dict)\n",
    "aa_dict_no_cys.pop('C')\n",
    "aa_dict_no_cys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrel_df = barrel_df[barrel_df['fasta_seq'] != 'C']\n",
    "barrel_df = barrel_df.reset_index(drop=True)\n",
    "\n",
    "barrel_distribution = calc_distribution(barrel_df, aa_dict)\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='FASTA', y='Normalised frequency', data=barrel_distribution)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aa in list(aa_dict_no_cys.keys()):\n",
    "    print(aa + ': ' + str(barrel_df['fasta_seq'].tolist().count(aa)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this distribution compare to those previously determined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levitt_dict = OrderedDict({'A': 0.900, 'R': 0.990, 'N': 0.760, 'D': 0.720, 'C': 0.740, 'Q': 0.800, 'E': 0.750,\n",
    "                           'G': 0.920, 'H': 1.080, 'I': 1.450, 'L': 1.020, 'K': 0.770, 'M': 0.970, 'F': 1.320,\n",
    "                           'P': 0.640, 'S': 0.950, 'T': 1.210, 'W': 1.140, 'Y': 1.250, 'V': 1.490})\n",
    "levitt_df = pd.DataFrame({'FASTA': list(levitt_dict.keys()),\n",
    "                          'Propensity': list(levitt_dict.values())})\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='FASTA', y='Propensity', data=levitt_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chou_fasman_dict = OrderedDict({'A': 0.830, 'R': 0.930, 'N': 0.890, 'D': 0.540, 'C': 1.190, 'Q': 1.100, 'E': 0.370,\n",
    "                                'G': 0.750, 'H': 0.870, 'I': 1.600, 'L': 1.300, 'K': 0.740, 'M': 1.050, 'F': 1.380, \n",
    "                                'P': 0.550, 'S': 0.750, 'T': 1.190, 'W': 1.370, 'Y': 1.470, 'V': 1.700})\n",
    "chou_fasman_df = pd.DataFrame({'FASTA': list(chou_fasman_dict.keys()),\n",
    "                               'Propensity': list(chou_fasman_dict.values())})\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='FASTA', y='Propensity', data=chou_fasman_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete propensity calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interior / exterior propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ext_propensity, int_ext_frequency, int_ext_normed_frequencies = calc_indv_property_propensities(\n",
    "    barrel_df, 'int_ext', aa_dict_no_cys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ext_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ext_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graphs(int_ext_propensity, 'Propensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graphs(int_ext_frequency, 'Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(int_ext_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(int_ext_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    int_ext_bootstrap_propensity_dict, int_ext_bootstrap_frequency_dict, int_ext_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, 'int_ext', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_indv_property_propensities,\n",
    "    int_ext_propensity, int_ext_frequency, int_ext_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    int_ext_conf_intv_propensity_dict, int_ext_conf_intv_frequency_dict, int_ext_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, 'int_ext', aa_dict_no_cys, 300, calc_indv_property_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lower_percentile_int_ext_propensity_dict, upper_percentile_int_ext_propensity_dict = gen_95_conf_intervals(\n",
    "    int_ext_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    int_ext_propensity, lower_percentile_int_ext_propensity_dict, upper_percentile_int_ext_propensity_dict,\n",
    "    'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lower_percentile_int_ext_frequency_dict, upper_percentile_int_ext_frequency_dict = gen_95_conf_intervals(\n",
    "    int_ext_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    int_ext_frequency, lower_percentile_int_ext_frequency_dict, upper_percentile_int_ext_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmembrane / external propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_ext_propensity, tm_ext_frequency, tm_ext_normed_frequencies = calc_indv_property_propensities(\n",
    "    barrel_df, 'tm_ext', aa_dict_no_cys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_ext_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_ext_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graphs(tm_ext_propensity, 'Propensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graphs(tm_ext_frequency, 'Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(tm_ext_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(tm_ext_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    tm_ext_bootstrap_propensity_dict, tm_ext_bootstrap_frequency_dict, tm_ext_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, 'tm_ext', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_indv_property_propensities, tm_ext_propensity,\n",
    "    tm_ext_frequency, tm_ext_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    tm_ext_conf_intv_propensity_dict, tm_ext_conf_intv_frequency_dict, tm_ext_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, 'tm_ext', aa_dict_no_cys, 300, calc_indv_property_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lower_percentile_tm_ext_propensity_dict, upper_percentile_tm_ext_propensity_dict = gen_95_conf_intervals(\n",
    "    tm_ext_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    tm_ext_propensity, lower_percentile_tm_ext_propensity_dict, upper_percentile_tm_ext_propensity_dict,\n",
    "    'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lower_percentile_tm_ext_frequency_dict, upper_percentile_tm_ext_frequency_dict = gen_95_conf_intervals(\n",
    "    tm_ext_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    tm_ext_frequency, lower_percentile_tm_ext_frequency_dict, upper_percentile_tm_ext_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All combinations propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(int_ext_tm_ext_propensity, int_ext_tm_ext_frequency, int_ext_tm_ext_normed_frequencies\n",
    ") = calc_combined_property_propensities(\n",
    "    barrel_df, ['int_ext', 'tm_ext'], aa_dict_no_cys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ext_tm_ext_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ext_tm_ext_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graphs(int_ext_tm_ext_propensity, 'Propensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graphs(int_ext_tm_ext_frequency, 'Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(int_ext_tm_ext_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(int_ext_tm_ext_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    int_ext_tm_ext_bootstrap_propensity_dict, int_ext_tm_ext_bootstrap_frequency_dict,\n",
    "    int_ext_tm_ext_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, ['int_ext', 'tm_ext'], aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_combined_property_propensities,\n",
    "    int_ext_tm_ext_propensity, int_ext_tm_ext_frequency, int_ext_tm_ext_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    int_ext_tm_ext_conf_intv_propensity_dict, int_ext_tm_ext_conf_intv_frequency_dict,\n",
    "    int_ext_tm_ext_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, ['int_ext', 'tm_ext'], aa_dict_no_cys, 300, calc_combined_property_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_int_ext_tm_ext_propensity_dict, upper_percentile_int_ext_tm_ext_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    int_ext_tm_ext_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    int_ext_tm_ext_propensity, lower_percentile_int_ext_tm_ext_propensity_dict,\n",
    "    upper_percentile_int_ext_tm_ext_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_int_ext_tm_ext_frequency_dict, upper_percentile_int_ext_tm_ext_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    int_ext_tm_ext_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    int_ext_tm_ext_frequency, lower_percentile_int_ext_tm_ext_frequency_dict,\n",
    "    upper_percentile_int_ext_tm_ext_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phi psi discrete bin propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_cluster_coords, discrete_phi_psi_cluster_dataframe = calc_voronoi_points(barrel_df, 'phi', 'psi', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vor = scipy.spatial.Voronoi(discrete_phi_psi_cluster_coords)\n",
    "\n",
    "plt.clf()\n",
    "scipy.spatial.voronoi_plot_2d(vor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(discrete_phi_psi_propensity, discrete_phi_psi_frequency, discrete_phi_psi_normed_frequencies\n",
    ") = calc_discrete_2d_indv_aa_propensities(barrel_df, 'phi', 'psi', aa_dict_no_cys, discrete_phi_psi_cluster_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(discrete_phi_psi_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(discrete_phi_psi_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    discrete_phi_psi_bootstrap_propensity_dict, discrete_phi_psi_bootstrap_frequency_dict,\n",
    "    discrete_phi_psi_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, ['phi', 'psi'], aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_discrete_2d_indv_aa_propensities,\n",
    "    discrete_phi_psi_propensity, discrete_phi_psi_frequency, discrete_phi_psi_normed_frequencies, 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    discrete_phi_psi_conf_intv_propensity_dict, discrete_phi_psi_conf_intv_frequency_dict,\n",
    "    discrete_phi_psi_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, ['phi', 'psi'], aa_dict_no_cys, 300, calc_discrete_2d_indv_aa_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lower_percentile_discrete_phi_psi_propensity_dict, upper_percentile_discrete_phi_psi_propensity_dict = gen_95_conf_intervals(\n",
    "    discrete_phi_psi_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    discrete_phi_psi_propensity, lower_percentile_discrete_phi_psi_propensity_dict,\n",
    "    upper_percentile_discrete_phi_psi_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lower_percentile_discrete_phi_psi_frequency_dict, upper_percentile_discrete_phi_psi_frequency_dict = gen_95_conf_intervals(\n",
    "    discrete_phi_psi_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    discrete_phi_psi_frequency, lower_percentile_discrete_phi_psi_frequency_dict,\n",
    "    upper_percentile_discrete_phi_psi_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_int_cluster_coords, discrete_phi_psi_int_cluster_dataframe = calc_voronoi_points(\n",
    "    int_barrel_df, 'phi', 'psi', 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vor = scipy.spatial.Voronoi(discrete_phi_psi_int_cluster_coords)\n",
    "\n",
    "plt.clf()\n",
    "scipy.spatial.voronoi_plot_2d(int_vor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(discrete_phi_psi_int_propensity, discrete_phi_psi_int_frequency, discrete_phi_psi_int_normed_frequencies\n",
    ") = calc_discrete_2d_indv_aa_propensities(\n",
    "    int_barrel_df, 'phi', 'psi', aa_dict_no_cys, discrete_phi_psi_int_cluster_coords\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_int_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_int_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(discrete_phi_psi_int_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(discrete_phi_psi_int_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    discrete_phi_psi_int_bootstrap_propensity_dict, discrete_phi_psi_int_bootstrap_frequency_dict,\n",
    "    discrete_phi_psi_int_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    int_barrel_df, ['phi', 'psi'], aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_discrete_2d_indv_aa_propensities,\n",
    "    discrete_phi_psi_int_propensity, discrete_phi_psi_int_frequency, discrete_phi_psi_int_normed_frequencies, 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    discrete_phi_psi_int_conf_intv_propensity_dict, discrete_phi_psi_int_conf_intv_frequency_dict,\n",
    "    discrete_phi_psi_int_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    int_barrel_df, ['phi', 'psi'], aa_dict_no_cys, 300, calc_discrete_2d_indv_aa_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_discrete_phi_psi_int_propensity_dict, upper_percentile_discrete_phi_psi_int_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    discrete_phi_psi_int_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    discrete_phi_psi_int_propensity, lower_percentile_discrete_phi_psi_int_propensity_dict,\n",
    "    upper_percentile_discrete_phi_psi_int_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_discrete_phi_psi_int_frequency_dict, upper_percentile_discrete_phi_psi_int_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    discrete_phi_psi_int_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    discrete_phi_psi_int_frequency, lower_percentile_discrete_phi_psi_int_frequency_dict,\n",
    "    upper_percentile_discrete_phi_psi_int_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_ext_cluster_coords, discrete_phi_psi_ext_cluster_dataframe = calc_voronoi_points(\n",
    "    ext_barrel_df, 'phi', 'psi', 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_vor = scipy.spatial.Voronoi(discrete_phi_psi_ext_cluster_coords)\n",
    "\n",
    "plt.clf()\n",
    "scipy.spatial.voronoi_plot_2d(ext_vor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(discrete_phi_psi_ext_propensity, discrete_phi_psi_ext_frequency, discrete_phi_psi_ext_normed_frequencies\n",
    ") = calc_discrete_2d_indv_aa_propensities(\n",
    "    ext_barrel_df, 'phi', 'psi', aa_dict_no_cys, discrete_phi_psi_ext_cluster_coords\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_ext_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_phi_psi_ext_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(discrete_phi_psi_ext_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(discrete_phi_psi_ext_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    discrete_phi_psi_ext_bootstrap_propensity_dict, discrete_phi_psi_ext_bootstrap_frequency_dict,\n",
    "    discrete_phi_psi_ext_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    ext_barrel_df, ['phi', 'psi'], aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_discrete_2d_indv_aa_propensities,\n",
    "    discrete_phi_psi_ext_propensity, discrete_phi_psi_ext_frequency, discrete_phi_psi_ext_normed_frequencies, 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    discrete_phi_psi_ext_conf_intv_propensity_dict, discrete_phi_psi_ext_conf_intv_frequency_dict,\n",
    "    discrete_phi_psi_ext_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    ext_barrel_df, ['phi', 'psi'], aa_dict_no_cys, 300, calc_discrete_2d_indv_aa_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_discrete_phi_psi_ext_propensity_dict, upper_percentile_discrete_phi_psi_ext_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    discrete_phi_psi_ext_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    discrete_phi_psi_ext_propensity, lower_percentile_discrete_phi_psi_ext_propensity_dict,\n",
    "    upper_percentile_discrete_phi_psi_ext_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_discrete_phi_psi_ext_frequency_dict, upper_percentile_discrete_phi_psi_ext_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    discrete_phi_psi_ext_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    discrete_phi_psi_ext_frequency, lower_percentile_discrete_phi_psi_ext_frequency_dict,\n",
    "    upper_percentile_discrete_phi_psi_ext_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amino acid pairs propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_barrel_df = barrel_df[barrel_df['int_ext'] == 'interior']\n",
    "int_barrel_df = int_barrel_df.reset_index(drop=True)\n",
    "\n",
    "ext_barrel_df = barrel_df[barrel_df['int_ext'] == 'exterior']\n",
    "ext_barrel_df = ext_barrel_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hydrogen bonding pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_aa_pairs = gen_neighbouring_pairs_list(barrel_df, 'hb_pairs', aa_dict_no_cys)\n",
    "(hb_aa_pair_propensity, hb_aa_pair_frequency, hb_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(hb_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(hb_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(hb_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    hb_aa_pair_bootstrap_propensity_dict, hb_aa_pair_bootstrap_frequency_dict,\n",
    "    hb_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, 'hb_pairs', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    hb_aa_pair_propensity, hb_aa_pair_frequency, hb_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hb_aa_pair_conf_intv_propensity_dict, hb_aa_pair_conf_intv_frequency_dict,\n",
    "    hb_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, 'hb_pairs', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_hb_aa_pair_propensity_dict, upper_percentile_hb_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    hb_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    hb_aa_pair_propensity, lower_percentile_hb_aa_pair_propensity_dict,\n",
    "    upper_percentile_hb_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_hb_aa_pair_frequency_dict, upper_percentile_hb_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    hb_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    hb_aa_pair_frequency, lower_percentile_hb_aa_pair_frequency_dict,\n",
    "    upper_percentile_hb_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_int_aa_pairs = gen_neighbouring_pairs_list(int_barrel_df, 'hb_pairs', aa_dict_no_cys)\n",
    "(hb_int_aa_pair_propensity, hb_int_aa_pair_frequency, hb_int_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(hb_int_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_int_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_int_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(hb_int_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(hb_int_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    hb_int_aa_pair_bootstrap_propensity_dict, hb_int_aa_pair_bootstrap_frequency_dict,\n",
    "    hb_int_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    int_barrel_df, 'hb_pairs', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    hb_int_aa_pair_propensity, hb_int_aa_pair_frequency, hb_int_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hb_int_aa_pair_conf_intv_propensity_dict, hb_int_aa_pair_conf_intv_frequency_dict,\n",
    "    hb_int_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    int_barrel_df, 'hb_pairs', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_hb_int_aa_pair_propensity_dict, upper_percentile_hb_int_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    hb_int_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    hb_int_aa_pair_propensity, lower_percentile_hb_int_aa_pair_propensity_dict,\n",
    "    upper_percentile_hb_int_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_hb_int_aa_pair_frequency_dict, upper_percentile_hb_int_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    hb_int_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    hb_int_aa_pair_frequency, lower_percentile_hb_int_aa_pair_frequency_dict,\n",
    "    upper_percentile_hb_int_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_ext_aa_pairs = gen_neighbouring_pairs_list(ext_barrel_df, 'hb_pairs', aa_dict_no_cys)\n",
    "(hb_ext_aa_pair_propensity, hb_ext_aa_pair_frequency, hb_ext_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(hb_ext_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_ext_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_ext_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(hb_ext_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(hb_ext_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    hb_ext_aa_pair_bootstrap_propensity_dict, hb_ext_aa_pair_bootstrap_frequency_dict,\n",
    "    hb_ext_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    ext_barrel_df, 'hb_pairs', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    hb_ext_aa_pair_propensity, hb_ext_aa_pair_frequency, hb_ext_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hb_ext_aa_pair_conf_intv_propensity_dict, hb_ext_aa_pair_conf_intv_frequency_dict,\n",
    "    hb_ext_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    ext_barrel_df, 'hb_pairs', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_hb_ext_aa_pair_propensity_dict, upper_percentile_hb_ext_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    hb_ext_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    hb_ext_aa_pair_propensity, lower_percentile_hb_ext_aa_pair_propensity_dict,\n",
    "    upper_percentile_hb_ext_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_hb_ext_aa_pair_frequency_dict, upper_percentile_hb_ext_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    hb_ext_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    hb_ext_aa_pair_frequency, lower_percentile_hb_ext_aa_pair_frequency_dict,\n",
    "    upper_percentile_hb_ext_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non- hydrogen bonding pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_aa_pairs = gen_neighbouring_pairs_list(barrel_df, 'nhb_pairs', aa_dict_no_cys)\n",
    "(nhb_aa_pair_propensity, nhb_aa_pair_frequency, nhb_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(nhb_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(nhb_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(nhb_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    nhb_aa_pair_bootstrap_propensity_dict, nhb_aa_pair_bootstrap_frequency_dict,\n",
    "    nhb_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, 'nhb_pairs', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    nhb_aa_pair_propensity, nhb_aa_pair_frequency, nhb_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    nhb_aa_pair_conf_intv_propensity_dict, nhb_aa_pair_conf_intv_frequency_dict,\n",
    "    nhb_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, 'nhb_pairs', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_nhb_aa_pair_propensity_dict, upper_percentile_nhb_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    nhb_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    nhb_aa_pair_propensity, lower_percentile_nhb_aa_pair_propensity_dict,\n",
    "    upper_percentile_nhb_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_nhb_aa_pair_frequency_dict, upper_percentile_nhb_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    nhb_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    nhb_aa_pair_frequency, lower_percentile_nhb_aa_pair_frequency_dict,\n",
    "    upper_percentile_nhb_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_int_aa_pairs = gen_neighbouring_pairs_list(int_barrel_df, 'nhb_pairs', aa_dict_no_cys)\n",
    "(nhb_int_aa_pair_propensity, nhb_int_aa_pair_frequency, nhb_int_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(nhb_int_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_int_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_int_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(nhb_int_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(nhb_int_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    nhb_int_aa_pair_bootstrap_propensity_dict, nhb_int_aa_pair_bootstrap_frequency_dict,\n",
    "    nhb_int_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    int_barrel_df, 'nhb_pairs', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    nhb_int_aa_pair_propensity, nhb_int_aa_pair_frequency, nhb_int_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    nhb_int_aa_pair_conf_intv_propensity_dict, nhb_int_aa_pair_conf_intv_frequency_dict,\n",
    "    nhb_int_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    int_barrel_df, 'nhb_pairs', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_nhb_int_aa_pair_propensity_dict, upper_percentile_nhb_int_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    nhb_int_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    nhb_int_aa_pair_propensity, lower_percentile_nhb_int_aa_pair_propensity_dict,\n",
    "    upper_percentile_nhb_int_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_nhb_int_aa_pair_frequency_dict, upper_percentile_nhb_int_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    nhb_int_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    nhb_int_aa_pair_frequency, lower_percentile_nhb_int_aa_pair_frequency_dict,\n",
    "    upper_percentile_nhb_int_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_ext_aa_pairs = gen_neighbouring_pairs_list(ext_barrel_df, 'nhb_pairs', aa_dict_no_cys)\n",
    "(nhb_ext_aa_pair_propensity, nhb_ext_aa_pair_frequency, nhb_ext_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(nhb_ext_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_ext_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_ext_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(nhb_ext_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(nhb_ext_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    nhb_ext_aa_pair_bootstrap_propensity_dict, nhb_ext_aa_pair_bootstrap_frequency_dict,\n",
    "    nhb_ext_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    ext_barrel_df, 'nhb_pairs', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    nhb_ext_aa_pair_propensity, nhb_ext_aa_pair_frequency, nhb_ext_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    nhb_ext_aa_pair_conf_intv_propensity_dict, nhb_ext_aa_pair_conf_intv_frequency_dict,\n",
    "    nhb_ext_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    ext_barrel_df, 'nhb_pairs', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_nhb_ext_aa_pair_propensity_dict, upper_percentile_nhb_ext_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    nhb_ext_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    nhb_ext_aa_pair_propensity, lower_percentile_nhb_ext_aa_pair_propensity_dict,\n",
    "    upper_percentile_nhb_ext_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_nhb_ext_aa_pair_frequency_dict, upper_percentile_nhb_ext_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    nhb_ext_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    nhb_ext_aa_pair_frequency, lower_percentile_nhb_ext_aa_pair_frequency_dict,\n",
    "    upper_percentile_nhb_ext_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minus 2 pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "minus2_aa_pairs = gen_neighbouring_pairs_list(barrel_df, 'minus_2', aa_dict_no_cys)\n",
    "(minus2_aa_pair_propensity, minus2_aa_pair_frequency, minus2_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(minus2_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(minus2_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(minus2_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    minus2_aa_pair_bootstrap_propensity_dict, minus2_aa_pair_bootstrap_frequency_dict,\n",
    "    minus2_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, 'minus_2', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    minus2_aa_pair_propensity, minus2_aa_pair_frequency, minus2_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    minus2_aa_pair_conf_intv_propensity_dict, minus2_aa_pair_conf_intv_frequency_dict,\n",
    "    minus2_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, 'minus_2', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_minus2_aa_pair_propensity_dict, upper_percentile_minus2_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    minus2_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    minus2_aa_pair_propensity, lower_percentile_minus2_aa_pair_propensity_dict,\n",
    "    upper_percentile_minus2_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_minus2_aa_pair_frequency_dict, upper_percentile_minus2_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    minus2_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    minus2_aa_pair_frequency, lower_percentile_minus2_aa_pair_frequency_dict,\n",
    "    upper_percentile_minus2_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2_int_aa_pairs = gen_neighbouring_pairs_list(int_barrel_df, 'minus_2', aa_dict_no_cys)\n",
    "(minus2_int_aa_pair_propensity, minus2_int_aa_pair_frequency, minus2_int_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(minus2_int_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2_int_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2_int_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(minus2_int_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(minus2_int_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    minus2_int_aa_pair_bootstrap_propensity_dict, minus2_int_aa_pair_bootstrap_frequency_dict,\n",
    "    minus2_int_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    int_barrel_df, 'minus_2', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    minus2_int_aa_pair_propensity, minus2_int_aa_pair_frequency, minus2_int_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    minus2_int_aa_pair_conf_intv_propensity_dict, minus2_int_aa_pair_conf_intv_frequency_dict,\n",
    "    minus2_int_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    int_barrel_df, 'minus_2', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_minus2_int_aa_pair_propensity_dict, upper_percentile_minus2_int_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    minus2_int_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    minus2_int_aa_pair_propensity, lower_percentile_minus2_int_aa_pair_propensity_dict,\n",
    "    upper_percentile_minus2_int_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_minus2_int_aa_pair_frequency_dict, upper_percentile_minus2_int_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    minus2_int_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    minus2_int_aa_pair_frequency, lower_percentile_minus2_int_aa_pair_frequency_dict,\n",
    "    upper_percentile_minus2_int_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "minus2_ext_aa_pairs = gen_neighbouring_pairs_list(ext_barrel_df, 'minus_2', aa_dict_no_cys)\n",
    "(minus2_ext_aa_pair_propensity, minus2_ext_aa_pair_frequency, minus2_ext_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(minus2_ext_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2_ext_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2_ext_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(minus2_ext_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(minus2_ext_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    minus2_ext_aa_pair_bootstrap_propensity_dict, minus2_ext_aa_pair_bootstrap_frequency_dict,\n",
    "    minus2_ext_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    ext_barrel_df, 'minus_2', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    minus2_ext_aa_pair_propensity, minus2_ext_aa_pair_frequency, minus2_ext_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    minus2_ext_aa_pair_conf_intv_propensity_dict, minus2_ext_aa_pair_conf_intv_frequency_dict,\n",
    "    minus2_ext_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    ext_barrel_df, 'minus_2', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_minus2_ext_aa_pair_propensity_dict, upper_percentile_minus2_ext_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    minus2_ext_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    minus2_ext_aa_pair_propensity, lower_percentile_minus2_ext_aa_pair_propensity_dict,\n",
    "    upper_percentile_minus2_ext_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_minus2_ext_aa_pair_frequency_dict, upper_percentile_minus2_ext_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    minus2_ext_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    minus2_ext_aa_pair_frequency, lower_percentile_minus2_ext_aa_pair_frequency_dict,\n",
    "    upper_percentile_minus2_ext_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plus 2 pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_aa_pairs = gen_neighbouring_pairs_list(barrel_df, 'plus_2', aa_dict_no_cys)\n",
    "(plus2_aa_pair_propensity, plus2_aa_pair_frequency, plus2_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(plus2_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(plus2_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(plus2_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    plus2_aa_pair_bootstrap_propensity_dict, plus2_aa_pair_bootstrap_frequency_dict,\n",
    "    plus2_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, 'plus_2', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    plus2_aa_pair_propensity, plus2_aa_pair_frequency, plus2_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    plus2_aa_pair_conf_intv_propensity_dict, plus2_aa_pair_conf_intv_frequency_dict,\n",
    "    plus2_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, 'plus_2', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_plus2_aa_pair_propensity_dict, upper_percentile_plus2_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    plus2_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    plus2_aa_pair_propensity, lower_percentile_plus2_aa_pair_propensity_dict,\n",
    "    upper_percentile_plus2_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_plus2_aa_pair_frequency_dict, upper_percentile_plus2_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    plus2_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    plus2_aa_pair_frequency, lower_percentile_plus2_aa_pair_frequency_dict,\n",
    "    upper_percentile_plus2_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_int_aa_pairs = gen_neighbouring_pairs_list(int_barrel_df, 'plus_2', aa_dict_no_cys)\n",
    "(plus2_int_aa_pair_propensity, plus2_int_aa_pair_frequency, plus2_int_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(plus2_int_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_int_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_int_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(plus2_int_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(plus2_int_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    plus2_int_aa_pair_bootstrap_propensity_dict, plus2_int_aa_pair_bootstrap_frequency_dict,\n",
    "    plus2_int_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    int_barrel_df, 'plus_2', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    plus2_int_aa_pair_propensity, plus2_int_aa_pair_frequency, plus2_int_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    plus2_int_aa_pair_conf_intv_propensity_dict, plus2_int_aa_pair_conf_intv_frequency_dict,\n",
    "    plus2_int_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    int_barrel_df, 'plus_2', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_plus2_int_aa_pair_propensity_dict, upper_percentile_plus2_int_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    plus2_int_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    plus2_int_aa_pair_propensity, lower_percentile_plus2_int_aa_pair_propensity_dict,\n",
    "    upper_percentile_plus2_int_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_plus2_int_aa_pair_frequency_dict, upper_percentile_plus2_int_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    plus2_int_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    plus2_int_aa_pair_frequency, lower_percentile_plus2_int_aa_pair_frequency_dict,\n",
    "    upper_percentile_plus2_int_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_ext_aa_pairs = gen_neighbouring_pairs_list(ext_barrel_df, 'plus_2', aa_dict_no_cys)\n",
    "(plus2_ext_aa_pair_propensity, plus2_ext_aa_pair_frequency, plus2_ext_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(plus2_ext_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_ext_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus2_ext_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(plus2_ext_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(plus2_ext_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    plus2_ext_aa_pair_bootstrap_propensity_dict, plus2_ext_aa_pair_bootstrap_frequency_dict,\n",
    "    plus2_ext_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    ext_barrel_df, 'plus_2', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    plus2_ext_aa_pair_propensity, plus2_ext_aa_pair_frequency, plus2_ext_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    plus2_ext_aa_pair_conf_intv_propensity_dict, plus2_ext_aa_pair_conf_intv_frequency_dict,\n",
    "    plus2_ext_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    ext_barrel_df, 'plus_2', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_plus2_ext_aa_pair_propensity_dict, upper_percentile_plus2_ext_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    plus2_ext_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    plus2_ext_aa_pair_propensity, lower_percentile_plus2_ext_aa_pair_propensity_dict,\n",
    "    upper_percentile_plus2_ext_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_plus2_ext_aa_pair_frequency_dict, upper_percentile_plus2_ext_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    plus2_ext_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    plus2_ext_aa_pair_frequency, lower_percentile_plus2_ext_aa_pair_frequency_dict,\n",
    "    upper_percentile_plus2_ext_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairs in Van der Waals contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_aa_pairs = gen_neighbouring_pairs_list(barrel_df, 'van_der_waals', aa_dict_no_cys)\n",
    "(vdw_aa_pair_propensity, vdw_aa_pair_frequency, vdw_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(vdw_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(vdw_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(vdw_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    vdw_aa_pair_bootstrap_propensity_dict, vdw_aa_pair_bootstrap_frequency_dict,\n",
    "    vdw_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    barrel_df, 'van_der_waals', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    vdw_aa_pair_propensity, vdw_aa_pair_frequency, vdw_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vdw_aa_pair_conf_intv_propensity_dict, vdw_aa_pair_conf_intv_frequency_dict,\n",
    "    vdw_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    barrel_df, 'van_der_waals', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_vdw_aa_pair_propensity_dict, upper_percentile_vdw_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    vdw_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    vdw_aa_pair_propensity, lower_percentile_vdw_aa_pair_propensity_dict,\n",
    "    upper_percentile_vdw_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_vdw_aa_pair_frequency_dict, upper_percentile_vdw_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    vdw_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    vdw_aa_pair_frequency, lower_percentile_vdw_aa_pair_frequency_dict,\n",
    "    upper_percentile_vdw_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_int_aa_pairs = gen_neighbouring_pairs_list(int_barrel_df, 'van_der_waals', aa_dict_no_cys)\n",
    "(vdw_int_aa_pair_propensity, vdw_int_aa_pair_frequency, vdw_int_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(vdw_int_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_int_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_int_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(vdw_int_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(vdw_int_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    vdw_int_aa_pair_bootstrap_propensity_dict, vdw_int_aa_pair_bootstrap_frequency_dict,\n",
    "    vdw_int_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    int_barrel_df, 'van_der_waals', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    vdw_int_aa_pair_propensity, vdw_int_aa_pair_frequency, vdw_int_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vdw_int_aa_pair_conf_intv_propensity_dict, vdw_int_aa_pair_conf_intv_frequency_dict,\n",
    "    vdw_int_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    int_barrel_df, 'van_der_waals', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_vdw_int_aa_pair_propensity_dict, upper_percentile_vdw_int_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    vdw_int_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    vdw_int_aa_pair_propensity, lower_percentile_vdw_int_aa_pair_propensity_dict,\n",
    "    upper_percentile_vdw_int_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_vdw_int_aa_pair_frequency_dict, upper_percentile_vdw_int_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    vdw_int_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    vdw_int_aa_pair_frequency, lower_percentile_vdw_int_aa_pair_frequency_dict,\n",
    "    upper_percentile_vdw_int_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_ext_aa_pairs = gen_neighbouring_pairs_list(ext_barrel_df, 'van_der_waals', aa_dict_no_cys)\n",
    "(vdw_ext_aa_pair_propensity, vdw_ext_aa_pair_frequency, vdw_ext_aa_pair_normed_frequencies\n",
    ") = calc_aa_pair_propensities(vdw_ext_aa_pairs, aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_ext_aa_pair_propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdw_ext_aa_pair_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(vdw_ext_aa_pair_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_map(vdw_ext_aa_pair_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    vdw_ext_aa_pair_bootstrap_propensity_dict, vdw_ext_aa_pair_bootstrap_frequency_dict,\n",
    "    vdw_ext_aa_pair_bootstrap_normed_frequencies_dict\n",
    ") = iterate_bootstrap_propensities(\n",
    "    ext_barrel_df, 'van_der_waals', aa_dict_no_cys, [10, 30, 100, 300, 1000], calc_aa_pair_propensities,\n",
    "    vdw_ext_aa_pair_propensity, vdw_ext_aa_pair_frequency, vdw_ext_aa_pair_normed_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vdw_ext_aa_pair_conf_intv_propensity_dict, vdw_ext_aa_pair_conf_intv_frequency_dict,\n",
    "    vdw_ext_aa_pair_conf_intv_normed_frequencies_dict\n",
    ") = bootstrap_discrete_propensities(\n",
    "    ext_barrel_df, 'van_der_waals', aa_dict_no_cys, 300, calc_aa_pair_propensities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_vdw_ext_aa_pair_propensity_dict, upper_percentile_vdw_ext_aa_pair_propensity_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    vdw_ext_aa_pair_conf_intv_propensity_dict, 'Propensity'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    vdw_ext_aa_pair_propensity, lower_percentile_vdw_ext_aa_pair_propensity_dict,\n",
    "    upper_percentile_vdw_ext_aa_pair_propensity_dict, 'Propensity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lower_percentile_vdw_ext_aa_pair_frequency_dict, upper_percentile_vdw_ext_aa_pair_frequency_dict\n",
    ") = gen_95_conf_intervals(\n",
    "    vdw_ext_aa_pair_conf_intv_frequency_dict, 'Frequency'\n",
    ")\n",
    "plot_bar_graphs_with_conf_limits(\n",
    "    vdw_ext_aa_pair_frequency, lower_percentile_vdw_ext_aa_pair_frequency_dict,\n",
    "    upper_percentile_vdw_ext_aa_pair_frequency_dict, 'Frequency'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous propensity calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D individual amino acid propensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_aa_kdes(barrel_df, ['z_coords'], 'comparison', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_propensity = plot_1d_indv_aa_propensities(barrel_df, 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_aa_kdes(int_barrel_df, ['z_coords'], 'comparison', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_int_propensity = plot_1d_indv_aa_propensities(int_barrel_df, 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_aa_kdes(ext_barrel_df, ['z_coords'], 'comparison', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_ext_propensity = plot_1d_indv_aa_propensities(ext_barrel_df, 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D pairwise amino acid propensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hydrogen bonding pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_hb_propensity = plot_1d_pairwise_aa_propensities(barrel_df, 'hb_pairs', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_hb_int_propensity = plot_1d_pairwise_aa_propensities(int_barrel_df, 'hb_pairs', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_hb_ext_propensity = plot_1d_pairwise_aa_propensities(ext_barrel_df, 'hb_pairs', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non- hydrogen bonding pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_nhb_propensity = plot_1d_pairwise_aa_propensities(barrel_df, 'nhb_pairs', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_nhb_int_propensity = plot_1d_pairwise_aa_propensities(int_barrel_df, 'nhb_pairs', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_nhb_ext_propensity = plot_1d_pairwise_aa_propensities(ext_barrel_df, 'nhb_pairs', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minus 2 pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_minus2_propensity = plot_1d_pairwise_aa_propensities(barrel_df, 'minus_2', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_minus2_int_propensity = plot_1d_pairwise_aa_propensities(int_barrel_df, 'minus_2', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_minus2_ext_propensity = plot_1d_pairwise_aa_propensities(ext_barrel_df, 'minus_2', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plus 2 pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_plus2_propensity = plot_1d_pairwise_aa_propensities(barrel_df, 'plus_2', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_plus2_int_propensity = plot_1d_pairwise_aa_propensities(int_barrel_df, 'plus_2', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_plus2_ext_propensity = plot_1d_pairwise_aa_propensities(ext_barrel_df, 'plus_2', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Van der Waals pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_vdw_propensity = plot_1d_pairwise_aa_propensities(barrel_df, 'van_der_waals', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_vdw_int_propensity = plot_1d_pairwise_aa_propensities(int_barrel_df, 'van_der_waals', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_vdw_ext_propensity = plot_1d_pairwise_aa_propensities(ext_barrel_df, 'van_der_waals', 'z_coords', aa_dict_no_cys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D individual amino acid propensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont_phi_psi_propensity = plot_2d_indv_aa_propensities(barrel_df, 'phi', 'psi', aa_dict_no_cys,\n",
    "                                                       [-180, -60], [100, 180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_phi_psi_int_propensity = plot_2d_indv_aa_propensities(int_barrel_df, 'phi', 'psi', aa_dict_no_cys,\n",
    "                                                           [-180, -60], [100, 180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_phi_psi_ext_propensity = plot_2d_indv_aa_propensities(ext_barrel_df, 'phi', 'psi', aa_dict_no_cys,\n",
    "                                                           [-180, -60], [100, 180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves propensity and frequency dictionaries to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propensities_dict = OrderedDict({'int_-_-_-_hb_pair_disc_propensity': hb_int_aa_pair_propensity,\n",
    "                                 'ext_-_-_-_hb_pair_disc_propensity': hb_ext_aa_pair_propensity,\n",
    "                                 'int_-_-_-_nhb_pair_disc_propensity': nhb_int_aa_pair_propensity,\n",
    "                                 'ext_-_-_-_nhb_pair_disc_propensity': nhb_ext_aa_pair_propensity,\n",
    "                                 'int_-_-_-_plusminus2_pair_disc_propensity': minus2_int_aa_pair_propensity,\n",
    "                                 'ext_-_-_-_plusminus2_pair_disc_propensity': minus2_ext_aa_pair_propensity,\n",
    "                                 'int_-_-_-_vdw_pair_disc_propensity': vdw_int_aa_pair_propensity,\n",
    "                                 'ext_-_-_-_vdw_pair_disc_propensity': vdw_ext_aa_pair_propensity,\n",
    "                                 'int_-_z_-_-_indv_cont_propensity': z_int_propensity,\n",
    "                                 'ext_-_z_-_-_indv_cont_propensity': z_ext_propensity,\n",
    "                                 'int_-_z_-_hb_pair_cont_propensity': z_hb_int_propensity,\n",
    "                                 'ext_-_z_-_hb_pair_cont_propensity': z_hb_ext_propensity,\n",
    "                                 'int_-_z_-_nhb_pair_cont_propensity': z_nhb_int_propensity,\n",
    "                                 'ext_-_z_-_nhb_pair_cont_propensity': z_nhb_ext_propensity,\n",
    "                                 'int_-_z_-_plusminus2_pair_cont_propensity': z_minus2_int_propensity,\n",
    "                                 'ext_-_z_-_plusminus2_pair_cont_propensity': z_minus2_ext_propensity,\n",
    "                                 'int_-_z_-_vdw_pair_cont_propensity': z_vdw_int_propensity,\n",
    "                                 'ext_-_z_-_vdw_pair_cont_propensity': z_vdw_ext_propensity,\n",
    "                                 'int_-_phi_psi_-_indv_disc_propensity': discrete_phi_psi_int_propensity,\n",
    "                                 'ext_-_phi_psi_-_indv_disc_propensity': discrete_phi_psi_ext_propensity})\n",
    "\n",
    "with open('Pickled_propensity_dictionaries.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(propensities_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_dict = OrderedDict({'int_-_-_-_hb_pair_disc_frequency': hb_int_aa_pair_normed_frequencies,\n",
    "                                'ext_-_-_-_hb_pair_disc_frequency': hb_ext_aa_pair_normed_frequencies,\n",
    "                                'int_-_-_-_nhb_pair_disc_frequency': nhb_int_aa_pair_normed_frequencies,\n",
    "                                'ext_-_-_-_nhb_pair_disc_frequency': nhb_ext_aa_pair_normed_frequencies,\n",
    "                                'int_-_-_-_plusminus2_pair_disc_frequency': minus2_int_aa_pair_normed_frequencies,\n",
    "                                'ext_-_-_-_plusminus2_pair_disc_frequency': minus2_ext_aa_pair_normed_frequencies,\n",
    "                                'int_-_-_-_vdw_pair_disc_frequency': vdw_int_aa_pair_normed_frequencies,\n",
    "                                'ext_-_-_-_vdw_pair_disc_frequency': vdw_ext_aa_pair_normed_frequencies,\n",
    "                                'int_-_phi_psi_-_indv_disc_frequency': discrete_phi_psi_int_normed_frequencies,\n",
    "                                'ext_-_phi_psi_-_indv_disc_frequency': discrete_phi_psi_ext_normed_frequencies})\n",
    "\n",
    "with open('Pickled_frequency_dictionaries.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(frequencies_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Kolmogorov-Smirnov test to compare individual and overall amino acid z-coordinate distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "Both barrel surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bootstrap samples should I use (all residues)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterate_bootstrap_conf_limits(\n",
    "    barrel_df, 'z_coords', run_ks_2samp_test, [100, 300, 1000, 3000, 10000, 30000, 100000], aa_dict_no_cys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the differences I observe between individual amino acid and overall amino acid distributions significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initial_D_dict, initial_p_dict = initial_ks_test(barrel_df, 'z_coords', run_ks_2samp_test, aa_dict_no_cys)\n",
    "\n",
    "D_dict_bootstrap, p_dict_bootstrap = bootstrap_ks_test(barrel_df, 'z_coords', 10000, run_ks_2samp_test, aa_dict_no_cys)\n",
    "draw_plot(sns.violinplot, p_dict_bootstrap, 'Amino acid', 'p')\n",
    "\n",
    "barrel_conf_intv_p_dict = calc_95_conf_limits(initial_p_dict, p_dict_bootstrap)\n",
    "draw_plot(sns.swarmplot, barrel_conf_intv_p_dict, 'Amino acid', 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "Interior surface barrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bootstrap samples should I use (interior residues)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterate_bootstrap_conf_limits(\n",
    "    int_barrel_df, 'z_coords', run_ks_2samp_test, [100, 300, 1000, 3000, 10000, 30000, 100000], aa_dict_no_cys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the differences I observe between individual amino acid and overall amino acid distributions significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initial_D_dict_int, initial_p_dict_int = initial_ks_test(int_barrel_df, 'z_coords', run_ks_2samp_test, aa_dict_no_cys)\n",
    "\n",
    "D_dict_bootstrap_int, p_dict_bootstrap_int = bootstrap_ks_test(\n",
    "    int_barrel_df, 'z_coords', 10000, run_ks_2samp_test, aa_dict_no_cys\n",
    ")\n",
    "draw_plot(sns.violinplot, p_dict_bootstrap_int, 'Amino acid', 'p')\n",
    "\n",
    "barrel_conf_intv_p_dict_int = calc_95_conf_limits(initial_p_dict_int, p_dict_bootstrap_int)\n",
    "draw_plot(sns.swarmplot, barrel_conf_intv_p_dict_int, 'Amino acid', 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bootstrap samples should I use (exterior residues)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterate_bootstrap_conf_limits(\n",
    "    ext_barrel_df, 'z_coords', run_ks_2samp_test, [100, 300, 1000, 3000, 10000, 30000, 100000], aa_dict_no_cys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the differences I observe between individual amino acid and overall amino acid distributions significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initial_D_dict_ext, initial_p_dict_ext = initial_ks_test(ext_barrel_df, 'z_coords', run_ks_2samp_test, aa_dict_no_cys)\n",
    "\n",
    "D_dict_bootstrap_ext, p_dict_bootstrap_ext = bootstrap_ks_test(\n",
    "    ext_barrel_df, 'z_coords', 10000, run_ks_2samp_test, aa_dict_no_cys\n",
    ")\n",
    "draw_plot(sns.violinplot, p_dict_bootstrap_ext, 'Amino acid', 'p')\n",
    "\n",
    "barrel_conf_intv_p_dict_ext = calc_95_conf_limits(initial_p_dict_ext, p_dict_bootstrap_ext)\n",
    "draw_plot(sns.swarmplot, barrel_conf_intv_p_dict_ext, 'Amino acid', 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction type vs. z-coordinate KDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_discrete_prop_frequency_kdes(\n",
    "    barrel_df, 'z_coords', ['van_der_waals', 'h_bonds', 'ionic', 'ss_bonds', 'pi_pi_stacking', 'pi_pi_stacking_p',\n",
    "                            'pi_pi_stacking_l', 'pi_pi_stacking_n', 'pi_pi_stacking_t', 'cation_pi']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_discrete_prop_frequency_kdes(\n",
    "    int_barrel_df, 'z_coords', ['van_der_waals', 'h_bonds', 'ionic', 'ss_bonds', 'pi_pi_stacking', 'pi_pi_stacking_p',\n",
    "                                'pi_pi_stacking_l', 'pi_pi_stacking_n', 'pi_pi_stacking_t', 'cation_pi']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_discrete_prop_frequency_kdes(\n",
    "    ext_barrel_df, 'z_coords', ['van_der_waals', 'h_bonds', 'ionic', 'ss_bonds', 'pi_pi_stacking', 'pi_pi_stacking_p',\n",
    "                                'pi_pi_stacking_l', 'pi_pi_stacking_n', 'pi_pi_stacking_t', 'cation_pi']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard error of proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate HB / NHB standard error of proportion z-scores from count data in Dek's 1998 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dek_sandwich_hb_pairs_dict, dek_sandwich_hb_pairs_total = gen_dek_sandwich_dicts(aa_dict, 'hb')\n",
    "dek_sandwich_nhb_pairs_dict, dek_sandwich_nhb_pairs_total = gen_dek_sandwich_dicts(aa_dict, 'nhb')\n",
    "\n",
    "dek_sandwich_hb_nhb_z_scores, dek_sandwich_hb_nhb_ratios = calc_std_error_proportion(\n",
    "    aa_dict, dek_sandwich_hb_pairs_dict, dek_sandwich_nhb_pairs_dict, dek_sandwich_hb_pairs_total,\n",
    "    dek_sandwich_nhb_pairs_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dek_sandwich_hb_nhb_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dek_sandwich_hb_nhb_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_significant_z_scores(dek_sandwich_hb_nhb_z_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate HB / NHB standard error of proportion z-scores for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "barrel_df_hb_pairs_dict, barrel_df_hb_pairs_total = calc_pair_proportions(\n",
    "    barrel_df, 'hb_pairs', aa_dict_no_cys\n",
    ")\n",
    "barrel_df_nhb_pairs_dict, barrel_df_nhb_pairs_total = calc_pair_proportions(\n",
    "    barrel_df, 'nhb_pairs', aa_dict_no_cys\n",
    ")\n",
    "\n",
    "barrel_df_hb_nhb_z_scores, barrel_df_hb_nhb_ratios = calc_std_error_proportion(\n",
    "    aa_dict_no_cys, barrel_df_hb_pairs_dict, barrel_df_nhb_pairs_dict, barrel_df_hb_pairs_total,\n",
    "    barrel_df_nhb_pairs_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barrel_df_hb_nhb_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrel_df_hb_nhb_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_significant_z_scores(barrel_df_hb_nhb_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrel_df_dek_sandwich_z_diff_dict = calc_z_diff(barrel_df_hb_nhb_z_scores, dek_sandwich_hb_nhb_z_scores)\n",
    "barrel_df_dek_sandwich_z_diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior barrel surface (new dataset only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "int_barrel_df_hb_pairs_dict, int_barrel_df_hb_pairs_total = calc_pair_proportions(\n",
    "    int_barrel_df, 'hb_pairs', aa_dict_no_cys\n",
    ")\n",
    "int_barrel_df_nhb_pairs_dict, int_barrel_df_nhb_pairs_total = calc_pair_proportions(\n",
    "    int_barrel_df, 'nhb_pairs', aa_dict_no_cys\n",
    ")\n",
    "\n",
    "int_barrel_df_hb_nhb_z_scores, int_barrel_df_hb_nhb_ratios = calc_std_error_proportion(\n",
    "    aa_dict_no_cys, int_barrel_df_hb_pairs_dict, int_barrel_df_nhb_pairs_dict, int_barrel_df_hb_pairs_total,\n",
    "    int_barrel_df_nhb_pairs_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_barrel_df_hb_nhb_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int_barrel_df_hb_nhb_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_significant_z_scores(int_barrel_df_hb_nhb_z_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior barrel surface (new dataset only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ext_barrel_df_hb_pairs_dict, ext_barrel_df_hb_pairs_total = calc_pair_proportions(\n",
    "    ext_barrel_df, 'hb_pairs', aa_dict_no_cys\n",
    ")\n",
    "ext_barrel_df_nhb_pairs_dict, ext_barrel_df_nhb_pairs_total = calc_pair_proportions(\n",
    "    ext_barrel_df, 'nhb_pairs', aa_dict_no_cys\n",
    ")\n",
    "\n",
    "ext_barrel_df_hb_nhb_z_scores, ext_barrel_df_hb_nhb_ratios = calc_std_error_proportion(\n",
    "    aa_dict_no_cys, ext_barrel_df_hb_pairs_dict, ext_barrel_df_nhb_pairs_dict, ext_barrel_df_hb_pairs_total,\n",
    "    ext_barrel_df_nhb_pairs_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_barrel_df_hb_nhb_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ext_barrel_df_hb_nhb_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_significant_z_scores(ext_barrel_df_hb_nhb_z_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_discrete_2d_pairwise_aa_propensities(df, cont_prop_1, cont_prop_2, iteraction, aa_dict, cluster_coords):\n",
    "    \"\"\"\n",
    "    Calculates pairwise amino acid propensity values for bins in 2D property space.\n",
    "    NOTE: This function calculates the propensity for an amino acid pair to be found in a particular bin (as\n",
    "    compared with all other bins), rather than the propensity for one amino acid to interact with a second within\n",
    "    that bin.\n",
    "    Input: dataframe of barrel / sandwich properties, first (continuous) property of interest (specified via the\n",
    "           name of the corresponding column in the input dataframe), second (continuous) property of interest\n",
    "           (specified via the name of the corresponding column in the input dataframe), type of interaction between\n",
    "           the amino acids in each pair, dictionary of amino acid abbreviations, and coordinates of cluster centres\n",
    "    Returns: dataframe of propensity values, plus dataframes of frequency and normalised frequency values (since\n",
    "             propensity values can be skewed by very small sample sizes)\n",
    "    \"\"\"\n",
    "    df = df[  (~df[cont_prop_1].isin(['', 'NaN', 'nan', np.nan]))\n",
    "            & (~df[cont_prop_2].isin(['', 'NaN', 'nan', np.nan]))]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    neighbouring_pairs_list, props_dict = gen_neighbouring_pairs_list(\n",
    "        df, interaction, aa_dict, cont_prop_1, cont_prop_2\n",
    "    )\n",
    "    prop_1_dict = props_dict[cont_prop_1]\n",
    "    prop_2_dict = props_dict[cont_prop_2]\n",
    "\n",
    "    aa_1_aa_2_list = [''.join(aa_pair) for aa_pair in list(itertools.product(list(aa_dict.keys())))]\n",
    "    propensity_dict = OrderedDict({'FASTA': aa_1_aa_2_list})\n",
    "    frequency_dict = OrderedDict({'FASTA': aa_1_aa_2_list})\n",
    "    normed_frequencies_dict = OrderedDict({'FASTA': aa_1_aa_2_list})\n",
    "    voronoi_class_dict = OrderedDict()\n",
    "\n",
    "    for voronoi_index in range(cluster_coords.shape[0]):\n",
    "        voronoi_class_dict[voronoi_index] = []\n",
    "        propensity_dict[voronoi_index] = [np.nan]*len(aa_1_aa_2_list)\n",
    "        frequency_dict[voronoi_index] = [np.nan]*len(aa_1_aa_2_list)\n",
    "        normed_frequencies_dict[voronoi_index] = [np.nan]*len(aa_1_aa_2_list)\n",
    "\n",
    "    for pair in list(prop_1_dict.keys()):\n",
    "        prop_val_1 = prop_1_dict[pair][0]\n",
    "        prop_val_2 = prop_2_dict[pair][0]\n",
    "        prop_vals = np.array([prop_val_1, prop_val_2])\n",
    "        \n",
    "        distances = np.sqrt(np.sum(np.square(cluster_coords-prop_vals), axis=1))\n",
    "        voronoi_index = np.abs(distances).argmin()\n",
    "        voronoi_class_dict[voronoi_index].append(''.join(pair.split('_')[2:]))\n",
    "\n",
    "    for aa_1 in list(aa_dict.keys()):\n",
    "        for aa_2 in list(aa_dict.keys()):\n",
    "            aa_1_aa_2_index = aa_1_aa_2_list.index('{}{}'.format(aa_1, aa_2))\n",
    "\n",
    "            for voronoi_index in list(voronoi_class_dict.keys()):\n",
    "                class_aa_1_aa_2_count = voronoi_class_dict[voronoi_index].count('{}{}'.format(aa_1, aa_2))\n",
    "                class_all_aas_count = len(voronoi_class_dict[voronoi_index])\n",
    "                total_aa_1_aa_2_count = neighbouring_pairs_list.count('{}{}'.format(aa_1, aa_2))\n",
    "                total_count = len(neighbouring_pairs_list)\n",
    "\n",
    "                try:\n",
    "                    propensity_dict[voronoi_index][aa_1_aa_2_index] = (  (class_aa_1_aa_2_count / class_all_aas_count)\n",
    "                                                                       / (total_aa_1_aa_2_count / total_count))\n",
    "                    frequency_dict[voronoi_index][aa_1_aa_2_index] = copy.deepcopy(class_aa_1_aa_2_count)\n",
    "                    normed_frequencies_dict[voronoi_index][aa_1_aa_2_index] = class_aa_1_aa_2_count / class_all_aas_count\n",
    "                except ZeroDivisionError:\n",
    "                    pass\n",
    "\n",
    "    propensity_df = pd.DataFrame(propensity_dict)\n",
    "    frequency_df = pd.DataFrame(frequency_dict)\n",
    "    normed_frequencies_df = pd.DataFrame(normed_frequencies_dict)\n",
    "\n",
    "    return propensity_df, frequency_df, normed_frequencies_df\n",
    "\n",
    "\n",
    "def calc_discrete_binned_2d_pairwise_aa_propensities(df, cont_prop_1, cont_prop_2, iteraction, aa_dict,\n",
    "                                                     cluster_coords):\n",
    "    \"\"\"\n",
    "    Calculates pairwise amino acid propensity values for bins in 2D property space.\n",
    "    NOTE: This function calculates the propensity for one amino acid to interact with a second within a particular\n",
    "    bin, rather than the propensity of an amino acid to be found within that bin as compared to all others.\n",
    "    **Consequently, this calculation requires a large number of data points in each bin.**\n",
    "    Input: dataframe of barrel / sandwich properties, first (continuous) property of interest (specified via the\n",
    "           name of the corresponding column in the input dataframe), second (continuous) property of interest\n",
    "           (specified via the name of the corresponding column in the input dataframe), type of interaction between\n",
    "           the amino acids in each pair, dictionary of amino acid abbreviations, and coordinates of cluster centres\n",
    "    Returns: dataframe of propensity values, plus dataframes of frequency and normalised frequency values (since\n",
    "             propensity values can be skewed by very small sample sizes)\n",
    "    \"\"\"\n",
    "    df = df[  (~df[cont_prop_1].isin(['', 'NaN', 'nan', np.nan]))\n",
    "            & (~df[cont_prop_2].isin(['', 'NaN', 'nan', np.nan]))]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    neighbouring_pairs_list, props_dict = gen_neighbouring_pairs_list(\n",
    "        df, interaction, aa_dict, cont_prop_1, cont_prop_2\n",
    "    )\n",
    "    prop_1_dict = props_dict[cont_prop_1]\n",
    "    prop_2_dict = props_dict[cont_prop_2]\n",
    "\n",
    "    propensity_dict = OrderedDict()\n",
    "    frequency_dict = OrderedDict()\n",
    "    normed_frequencies_dict = OrderedDict()\n",
    "    voronoi_class_dict = OrderedDict()\n",
    "\n",
    "    for voronoi_index in range(cluster_coords.shape[0]):\n",
    "        voronoi_class_dict[voronoi_index] = []\n",
    "        propensity_dict[voronoi_index] = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "        frequency_dict[voronoi_index] = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "        normed_frequencies_dict[voronoi_index] = OrderedDict({'FASTA': list(aa_dict.keys())})\n",
    "\n",
    "    for pair in list(prop_1_dict.keys()):\n",
    "        prop_val_1 = prop_1_dict[pair][0]\n",
    "        prop_val_2 = prop_2_dict[pair][0]\n",
    "        prop_vals = np.array([prop_val_1, prop_val_2])\n",
    "\n",
    "        distances = np.sqrt(np.sum(np.square(cluster_coords-prop_vals), axis=1))\n",
    "        voronoi_index = np.abs(distances).argmin()\n",
    "        voronoi_class_dict[voronoi_index].append(''.join(pair.split('_')[2:]))\n",
    "\n",
    "    for voronoi_index in list(voronoi_class_dict.keys()):\n",
    "        for aa_1 in list(aa_dict.keys()):\n",
    "            propensity_dict[voronoi_index][aa_1] = [np.nan]*len(aa_dict)\n",
    "            frequency_dict[voronoi_index][aa_1] = [np.nan]*len(aa_dict)\n",
    "            normed_frequencies_dict[voronoi_index][aa_1] = [np.nan]*len(aa_dict)\n",
    "\n",
    "            for aa_2_index, aa_2 in list(aa_dict.keys()):\n",
    "                aa_1_aa_2_count = 0\n",
    "                aa_1_count = 0\n",
    "                aa_2_count = 0\n",
    "                all_aas_count = 0\n",
    "                for pair in voronoi_class_dict[voronoi_index]:\n",
    "                    all_aas_count += 1\n",
    "                    if pair[0] == aa_1:\n",
    "                        aa_1_count += 1\n",
    "                    if pair[1] == [aa_2]:\n",
    "                        aa_2_count += 1\n",
    "                    if pair[0] == aa_1 and pair[1] == aa_2:\n",
    "                        aa_1_aa_2_count += 1\n",
    "\n",
    "                try:\n",
    "                    frequency_dict[voronoi_index][aa_1][aa_2_index] = copy.deepcopy(aa_1_aa_2_count)\n",
    "                    normed_frequencies_dict[voronoi_index][aa_1][aa_2_index] = aa_1_aa_2_count / aa_1_count\n",
    "                    propensity_dict[voronoi_index][aa_1][aa_2_index] = (  (aa_1_aa_2_count / aa_1_count)\n",
    "                                                                        / (aa_2_count / all_aas_count))\n",
    "                except ZeroDivisionError:\n",
    "                    pass\n",
    "\n",
    "    for voronoi_index in list(propensity_dict.keys()):\n",
    "        propensity_dict[voronoi_index] = pd.DataFrame(propensity_dict[voronoi_index])\n",
    "        frequency_dict[voronoi_index] = pd.DataFrame(frequency_dict[voronoi_index])\n",
    "        normed_frequencies_dict[voronoi_index] = pd.DataFrame(normed_frequencies_dict[voronoi_index])\n",
    "\n",
    "    return propensity_dict, frequency_dict, normed_frequencies_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
